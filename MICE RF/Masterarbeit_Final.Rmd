---
title: "Random Forests for Multiple Imputation of Missing Data in the IDEFICS study"
subtitle: "Master Thesis"
author: "Zehui Bai"
course: 'University of Bremen'
address: "Vorstraße 22, 28359, Bremen"
field: "Medical Biometry / Biostatistics"
logo: Fotos/logo.png  # insert path to your logo
referee: |
 Referee: Prof. Dr. Vanessa Didelez, Dr. Ronja Foraita  
 Supervisor: Janine Witte
ID: 'Immatrikulationsnummer: 3183673'


abstract: |
 Multivariate Imputation by Chained Equations (MICE) is a multiple imputation method, which is a priority strategy dealing with missing values. Compared with the single imputation methods (such as the mean imputation), MICE can solve the estimation uncertainty caused by single imputation and obtain unbiased estimation. However, when interactions or non-linear effects are existing between variables, estimation using parametric MICE may be biased when interactions or non-linear effects are not correctly specified in the imputation model. With the development of machine learning technology, random forest (RF) provides another prospect for dealing with interactions and nonlinear effects between variables. As the non-parametric approach, random-forest-based MICE (MICE RF) does not need to specify interactions and nonlinear relationships in the imputation model. The performance using MICE RF may be superior to the parametric MICE method. 
 
 This thesis selected 5 complete variables based on IDEFICS data. After creating missing in explanatory variables under MAR (Missing At Random) performed 1000 simulations using parametric MICE PMM (Predictive Mean Matching) and MICE RF in the following 3 Settings respectively. The impact of the number of trees on MICE RF, the impacts of sample size and missing ratio on MICE PMM and MICE RF, and the impact of interaction and non-linearity in the imputation model on the performance of MICE PMM and MICE RF. Two analysis approaches linear regression and conditional independence test (focusing on Fisher's z-test) were used to compare the performance of MICE PMM and MICE RF.
  

# Insert/Change name of bibliogrphic files:
# bibliography: Refer/curie.bib
# csl: examples/apa6.csl  # citation style file


# Change the following lines only if you know what you are doing:
date: '`r format(Sys.Date(), "%d\\. %m\\. %Y")`'  # today
fontfamily: lmodern
fontsize: 11pt
graphics: null
papersize: 
geometry: margin=1.0in
classoption:
  - a4paper
  - oneside
  #- more options here, see rmarkdown documentation 
  # lang: de-De
lof: yes
lot: yes
toc: yes
numbersections: yes
UP_title: yes
UP_subtitle: yes
shaded_quote: no
output: 
  yart::yart
---


```{r setup, include=FALSE, echo = FALSE,message = FALSE, error = FALSE, warning = FALSE, fig.align="center"}
knitr::opts_chunk$set(echo = TRUE)

## for summarize
library("devtools")
```



```{r echo=F,message = FALSE, error = FALSE, warning = FALSE}
## Data preparation
load("~/Library/Mobile Documents/com~apple~CloudDocs/05. Masterarbeit/04_Masterarbeit/01_Data/data.RData")
data <- data[,c(2,3,4,7,9)]
names(data) <- c("age","sex","bmi","isced","waist")

## completet case, omit all rows that contain NA values
data$sex <- as.factor(data$sex)
data$isced <- as.factor(data$isced)

data_complete <- data[complete.cases(data),]
data_complete <- data_complete[data_complete$isced!="NaN",]

## refactor isced_max
data_complete$isced[data_complete$isced %in% c("0", "1")] <- "1"
data_complete$isced[data_complete$isced %in% c("5", "6")] <- "5"
data_complete$isced <- factor(data_complete$isced,levels = c("1","2","3","4","5"))

data_complete$log.waist <- log(data_complete$waist)
```










# Introduction

Missing data is a real problem often encountered in scientific practice. Many statistical analyses require complete data, but it is not reasonable to discard observations containing missing, because the important information may be lost, and the inferences drawn may be biased (Roderick et al., 2002). Under certain assumptions, the imputation of missing values can be a valuable alternative. If the data does not have any information lost, the observed covariance matrix can be reproduced correctly (STATA, 2020).

In statistics, the missing data element can be imputed with one value using single imputation procedures, such as mean imputation. However, single imputation may reduce correlations between imputed variables and underestimate variability (Roderick et al., 2002). As a solution, multiple imputation (MI) is applied more often, which considers the uncertainty of missing data by creating several different plausible imputed datasets. One common MI approach currently is Multivariate Imputation by Chained Equations (MICE), which is also called Full Conditional Specification (FCS). MICE is a general method to generate imputed values derived from the estimated conditional distribution of the imputed variable given other variables, and it is flexible and may obtain unbiased parameter estimation when the imputation model for the variable with missingness is appropriately specified (Van Buuren, 2012). However, parametric MICE (the "parametric" refers to the imputation model rather than the analysis model) has limitations in the large-scale dataset, it can lead to over-parameterization when too many variables are included in the imputation model and calculation problems may also occur (Loh et al., 2011). On the other hand, parametric MICE does not automatically contain interactions and nonlinearities in the imputation model. When the imputation model does not consider the important interactions or nonlinear terms in the analysis model, it may lead to bias (Tilling et al., 2016).

Recursive partitioning methods are tree-based machine learning technologies, which have the potential to be used in MICE (Burgette et al., 2010; Stekhoven et al., 2012; Doove et al., 2014; Shah et al., 2014) and have strengths in many situations, such as under small sample size, when the predictors are highly correlated with each other (interactions), or in the high-dimensional data set with large-scale predictors (Slade et al., 2020). At present, the commonly applied tree-based recursive partitioning approaches are the classifications and regression trees (CART) proposed by Breiman et al. (1984) and random forest (Breiman, 2001).


CART selects features and partitions the predictor space to divide the dataset, the unit subsets after the partition are relatively homogeneous (Burgette et al., 2010), thereby forming a decision tree model. When the target variable is discrete, it is defined as a classification tree, while the continuous variable is denoted as a regression tree. Compared with CART, the random forest is an ensemble learning method for classification or regression and is constructed with many decision trees. The random forest operates by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees (Ho, 1995). 

As a nonparametric technique, the random forest can accommodate nonlinearities and interactions and does not require a particular regression model to be specified (Burgette et al., 2010), it has the potential to perform well in MICE. Shah et al. (2014) compared the parametric MICE with the random forest-based MICE using Cox models in two simulation studies based on the CALIBER database. The results showed that when the partially observed variables depend on the fully observed variables in a non-linear manner, random forest MICE reduced the bias of parameter estimators and the confidence interval coverage was better. It is worth exploring whether MICE based on random forests has still advantaged in other databases, which is the thesis's motivation.


The IDEFICS database used in this thesis is the largest study about overweight and obesity problems of children between 2 and 10 years old in Europe. This thesis aims to design and conduct suitable simulation studies based on the IDEFICS data, the missing values under MAR (missing at random) in the explanatory variables were created based on the complete dataset. Under 3 settings, linear regression and conditional independence test (Fisher's z-test) were used as analysis methods to compare the performance of parametric MICE using predictive mean matching (MICE PMM) and random forest MICE (MICE RF).

The rest of this thesis is structured as follows: Chapter 2 introduces the IDEFICS database and the variables and analysis models used in this study. Chapter 3 describes MICE algorithms and the important assumptions and concepts related to the multiple imputation process. Chapter 4 focuses on the design of simulation studies. Chapter 5 shows the simulation studies results using linear regression and conditional independence test under 3 Settings. Chapter 6 discusses the results and states the limitations of this thesis. The last two Chapters list the simulation codes and references for this thesis.













# IDEFICS data

The IDEFICS (**I**dentification and prevention of **D**ietary- and lifestyle-induced health **EF**fects **I**n **C**hildren and infant**S**) study is the largest child cohort in Europe, with the overall aim to investigate the risk factors for non-communicable chronic diseases and disorders with focuses on overweight and obesity (Ahrens et al., 2017). A large spectrum of potential risk factors, including diet, lifestyles, psychosocial and genetic factors, was measured to examine the potential causal pathways and provide reliable data to support childhood obesity's international assessment of childhood obesity. 

<!-- which researched the associations between non-communicable chronic diseases or disorders of children and genes, social, cultural, environmental lifestyle behaviors, etc. (Ahrens et al., 2017).  -->

In total, a cohort of 16118 children aged 2 to 9 years from 8 European countries (Sweden, Germany, Hungary, Italy, Cyprus, Spain, Belgium, and Estonia) took part in the first population-based survey (baseline survey, referred to as $T_0$) in September 2007. The second survey (follow-up survey, referred to as $T_1$) was conducted after 2 years. 11043 children were reexamined from $T_0$, and 2543 children were newly recruited to determine the correlation between possible factors that influence the state of health observed at $T_0$ and $T_1$. 


| Varlabel     | Label                                             | Type                  |  Missing  |
|--------------|---------------------------------------------------|-----------------------|-----------|
| Age          | Age of the child [years]                          | Continuous variable   | 0.00%     |
| Sex          | Sex of the child: Boy [M] and Girl [F]            | Categorical variable  | 0.00%     |
| BMI          | BMI in percent of the distribution function according to Cole et al. (2012)| Continuous variable| 0.00%       |
| ISCED        | International Standard Classification of Education with ISCED level [1]~[5] | Categorical variable  |3.62%|
| Waist        | Waist circumference [cm]                          | Continuous variable   | 2.93%     |
Table:\centering Variables description in simulation datasets



In this thesis, the IDEFICS data from the baseline $T_0$ with a sample size of 16118 was used, 5 complete and relatively complete variables were selected, which is referred to as **Dataset A**. Table 1 introduces the brief description and types of 5 variables, as well as the missing ratio in Dataset A. The variables "age", "BMI", and "Sex" were completely observed, while the variables "ISCED" and "waist" were incomplete with 3.62% and 2.93% missing. In addition to the description in Table 1 “Label”, supplementary descriptions of variables “BMI” and "ISCED" are provided here. The variable "BMI" (in the IDEFICS database denoted as "bmi_pct_cole_12") was not measured using $${\displaystyle \mathrm {BMI} ={\frac {{\text{mass}}_{\text{kg}}}{{{\text{height}}_{\text{m}}}^{2}}},}$$ 
which was calculated as percent in [0,1] of the distribution function according to Cole et al. (2012). Because the "normal" BMI of boys and girls changes with age, in order to judge whether a BMI is "normal", the reference population should be used for standardization. The BMI value of the child has to be compared with other children of the same sex and the same age. E.g., the "BMI" value of a five-year-old boy is 0.97, it means that his BMI level is 97th percentile in the 5-year-old boy's reference population, which is considered overweight. The variable "ISCED" (in the IDEFICS database denoted as "isced_max") was the maximum ISCED level of both parents of the child (calculated from education and qualification level). According to ISCED Classification (2011), ISCED [1] means primary education or less; ISCED [2] indicates lower secondary education; ISCED [3] denotes upper secondary education; ISCED [4] represents upper secondary education post-secondary non-tertiary education; ISCED [5] signifies short-cycle tertiary education, bachelor or better.





|              |       |      N       |  Mean   |    SD   |   Min   |    Q1   |  Median   |    Q3   |   Max |
|--------------|-------|--------------|:-------:|:-------:|:-------:|:-------:|:---------:|:-------:|:-----:|
| Age          |       | 15084        |  6.02   |  1.78   |  2.00   |  4.50   |    6.30   |  7.60   |  9.90 |
| BMI          |       | 15084        |  0.57   |  0.30   |  0.00   |  0.32   |    0.59   |  0.85   |  1.00 |
| log.Waist    |       | 15084        |  3.99   |  0.12   |  3.24   |  3.91   |    3.97   |  4.05   |  4.59 |
| Sex          | [M]   | 7665 (50.8%) |         |         |         |         |           |         |       |
|              | [F]   | 7419 (49.2%) |         |         |         |         |           |         |       |
| ISCED        | [1]   | 269 (1.8%)   |         |         |         |         |           |         |       |
|              | [2]   | 1097 (7.3%)  |         |         |         |         |           |         |       |
|              | [3]   | 5125 (34.0%) |         |         |         |         |           |         |       |
|              | [4]   | 2450 (16.2%) |         |         |         |         |           |         |       |
|              | [5]   | 6143 (40.7%) |         |         |         |         |           |         |       |
Table:\centering Descriptive statistics in Dataset B

\begin{center}
\includegraphics[width=6in]{Fotos/Distribution_of_the_variables.png}
\begin{figure}[!h]
\caption{Distribution of the variables in Dataset B}
\end{figure}
\end{center}


Based on Dataset A, observations in Dataset A that have at least one missing value in the 5 considered variables were deleted, and the obtained complete dataset with a sample size of 15084 was denoted **Dataset B**. Table 2 illustrates the descriptive statistics of the variables in Dataset B and Figure 1 shows their distribution. The distribution of the variable "waist" in Figure 1 is skewed. The transformation "sqrt.waist" (the square root of the "waist") and "log.waist" (the logarithm of the "waist") have been tried, the skewness of "waist" after the two transformations were improved, but the log transformation was better, so this thesis used "log.waist" instead of "waist" for simulation. The simulation dataset (called **Dataset C**) was sampled from Dataset B using the method described in Section 4.1. The dataset generation process is shown in Figure 2, the sample size of Setting 1 and Setting 3 was n=2000 (default), Setting 2 changed to n=200 or n=1000.


```{r echo=F,message = FALSE, error = FALSE, warning = FALSE}
library(DiagrammeR)
library(DiagrammeRsvg)
library(rsvg)
library(magrittr)

graph <- grViz(
      "digraph flowchart {
      # node definitions with substituted label text
      node [fontname = Helvetica, shape = rectangle]        
      tab1 [label = '@@1']
      tab2 [label = '@@2']
      tab3 [label = '@@3']

      # edge definitions with the node IDs
      tab1 -> tab2;
      tab2 -> tab3;
      }

      [1]: 'Dataset A: the original IDEFICS baseline T0 dataset n=16118'
      [2]: 'Dataset B: the complete dataset n=15084'
      [3]: 'Dataset C: the simulations datasets n=2000 (default)'
      ")
# exports images
# graph %>% export_svg %>% charToRaw %>% rsvg_png("Fotos/Study_population.png")
# graph %>% export_svg %>% charToRaw %>% rsvg_pdf("Fotos/Study_population.pdf")
```

\begin{center}
\includegraphics[width=3.5in]{Fotos/Study_population.png}
\begin{figure}[!h]
\caption{Datasets generation in simualtion study}
\end{figure}
\end{center}


Regardless of the MICE methods, all datasets were first analyzed using linear regression models, where continuous variable "log.waist" was applied as the dependent variable and other 4 independent continuous and discrete variables ("age", "sex", "BMI", "ISCED") were treated as independent variables. The analysis model must be correctly specified, the misspecification of the analysis model may lead to artifacts in connection with missing values imputation, and bias in parameter estimation (Shah et al., 2014).


The complete Dataset B was used to determine the appropriate analysis model and examine the quadratic effects and interactions. The model selection was performed by the best subset method, 4 main independent variables, all two-way interactions of them and 2 quadratic terms of the continuous variables were firstly specified as a set of predictors ($\text{sex + age + bmi + isced} + \text{sex.age + sex.bmi + sex.isced + age.bmi + age.isced + bmi.isced} + \text{age}^2 + \text{bmi}^2$). The best subset method compared all possible analysis models using those predictors, then the model evaluation was carried out through the residual plot, AIC (Akaike-Information-Criterion), BIC (Bayesian-Information-Criterion), Mallow's Cp and Cross-Validation. The best-fitting analysis model in this thesis was $$\text{log.waist} =  \text{sex + age + bmi + isced} + \text{sex.age + age.bmi}.$$ This analysis model was used in all settings described in Section 4.2, it did not depend on how the imputation model changed. Table 3 shows the coefficient estimates based on Dataset B (Sex[M] and ISCED[1] are reference categories), the estimates were considered as the true values when evaluating Monte Carlo bias (Section 4.3.1).



```{r echo=F,message = FALSE, error = FALSE, warning = FALSE}
data_complete <- data_complete[-5]

best.fit <- lm(log.waist ~  age + bmi + sex + isced + sex:age + age:bmi, data = data_complete)
coef <- summary(best.fit)$coefficients[ ,1]
library(pander)
## pander(summary(best.fit))
## pander(best.fit)
```


-----------------------------------------------------
     Variable       Estimate    Std. Error   P-value  
------------------ ----------- ------------ --------- 
   (Intercept)       3.7780      0.0061     <0.001

       Age           0.0110      0.0007     <0.001

       BMI           0.0392      0.0066     <0.001

      Sex[F]        -0.0022      0.0039     0.574   

      ISCED[2]       0.0092      0.0047     0.048   

      ISCED[3]       0.0029      0.0043     0.450   

      ISCED[4]       0.0076      0.0044     0.085

      ISCED[5]       0.0074      0.0043     0.083

      Age:Sex[F]    -0.0021      0.0006     <0.001

      Age:BMI        0.0354      0.0011     <0.001
------------------------------------------------------------------
Table:\centering Coefficients estimates of the analysis model in Dataset B



 
 

 
 


# Multiple imputation using MICE

In this section, the assumption Missing At Random (MAR) is firstly introduced, then the general procedures of multiple imputation, and the concepts of congeniality and compatibility. Finally, the algorithms of MICE PMM (parametric MICE using Predictive Mean Matching) and MICE RF (random forest MICE) used in this thesis are presented.





## Concept of MAR

Rubin (1976) defined three types of missing mechanisms, which describe the relationship between variables and the missing probability of data:

* Missing completely at random (MCAR) 
* Missing at random (MAR)
* Missing not at random (MNAR)

To better understand the three missing mechanisms, we can define:

* $\mathrm{X} = (X_0, X_1, ..., X_T)$ are observations of independent variables $\mathrm{X}$ (in this thesis, the dependent variable "waist" was fully observed, but the missingness of dependent variables also applies to the following mechanism),
* $\mathrm{X_{\text{obs}}}, \mathrm{X_{\text{miss}}}$ are observed and missing part of $\mathrm{X}$,
* $\mathrm{R} = (R_0, R_1, ..., R_T)$ is a vector of missingness indicators, where $R_t = 1$ if $X_t$ is observed and $R_t = 0$ otherwise, $t=1,...,T$.


Data are considered MCAR when the missing of observation is completely independent of the observed and the missing data, e.g., data missing due to measurement equipment failure. Under MCAR, for all missing patterns $\mathrm{r}$,
$$\mathbb{P} (\mathrm{R} = \mathrm{r} | \mathrm{X}) = \mathbb{P} (\mathrm{R} = \mathrm{r}).$$
The observed and missing data distribution is identical, data missing is completely unsystematic, and the observed (or missing) data are random sub-samples of complete data. Theoretically, estimation ignoring the missing values can provide unbiased results but maybe less precise (loss of power). However, MCAR is a strict assumption and is unlikely to be satisfied in practice, so this study did not assume MCAR.

This study assumed that the data missing were MAR. Compared with MCAR, MAR requires less strict assumptions about missing reasons. Under MAR, there is a connection between the probability of missingness and observed data. E.g., poor health of the patient at the study start may increase the possibility of research discontinuation. Formally, 
$$\mathbb{P} (\mathrm{R} = \mathrm{r} | \mathrm{X}) = \mathbb{P} (\mathrm{R} = \mathrm{r}|\mathrm{X_{\text{obs}}}).$$
Given the observed data, the probability of missing is independent of the missing value, the missing values can be predicted from the observed values. Although imputing predicted values without accounting for the uncertainty may lead to over-optimistic prediction (Roderick et al., 2002), multiple imputation can compensate for this. 

When the data is neither MCAR nor MAR, the probability of missing is systematically related to the missing observations, the data are MNAR, i.e., the probability of data being missing depends not only on observed but also on unobserved values. 
$$\mathbb{P} (\mathrm{R} = \mathrm{r} | \mathrm{X}) \neq \mathbb{P} (\mathrm{R} = \mathrm{r}|\mathrm{X_{\text{obs}}}).$$
E.g., patients with depression often do not provide information about their emotional state. However, the multiple imputation only applicable to MAR and MCAR, when the data contains MNAR, the parameter estimation using multiple imputation may be biased. 









## Multiple imputation

Multiple imputation (MI) was proposed by Rubin (1986). MI models the missing values by using the observed data distribution, each missing value is imputed with a set of reasonable values. At length, several complete imputed datasets are generated. Compared with single imputation, the main advantage of multiple imputation is that MI can reflect estimation variability under the same model using more imputed datasets. The following Figure 3 displays the multiple imputation process, and the algorithm is detailed in Table 4.


\begin{center}
\includegraphics[width=6.2in]{Fotos/MICE-process.png}
\begin{figure}[!h]
\caption{The multiple imputation process by Rubin (1986)}
\end{figure}
\end{center}


| |                       Algorithm 1: Multiple imputation                                |
|-|---------------------------------------------------------------------------------------|
|1.|**Imputation**: The missing data are imputed with random values generated from an explicit or implicit imputation model, and a completed dataset is created. This process repeats $m$ times ($m>1$).|
|2.|**Analysis**: These $m$ imputed datasets are analyzed using a statistical method of interest (linear regression and conditional independence test are applied separately in this thesis).|
|3.|**Pooling**: The final step combines the $m$ results from each imputed dataset. Take linear regression as an example, the parameter estimators $\theta_1,...,\theta_i,...,\theta_m$ drawn from the $m$ datasets are averaged: $\bar{\theta} = \frac{1}{m}\left (\sum_{i=1}^m{\theta_i}\right )$. The total variance $V_{\text{total}}$ is calculated by combining the within imputation variance and between imputation variance using Rubin (1987) formula $V_{\text{total}} = V_W + V_B + \frac{V_B}{m}$, where the within imputation variance $V_W$ is defined as $V_W = \frac{1}{m}\left (\sum_{i=1}^m{SE_i^2}\right)$, $SE_i^2$ is the sum of the squared Standard Error which is estimated in the imputed dataset; the between imputation variance $V_B$ is defined as $V_B=\sqrt{\frac{\sum_{i=1}^m (\theta_i - \overline{\theta})^2}{N-1}}.$|
Table:\centering Algorithm 1: Multiple imputation

 







## Bayesian linear regression


Although Bayesian linear regression is not one of the research methods of this thesis, the concept of "Compatibility and Congeniality" (Section 3.4), the MICE PMM algorithm used in thesis (Section 3.6), are related to Bayesian linear regression. To achieve the readability of this thesis, here is a brief introduction to Bayesian linear regression.

Imputation using linear regression is a simple imputation mothod, the regression model $y_{\text{obs}}=\hat\beta_0+X_{\text{obs}}\hat\beta_1$ is calculated from the complete dataset ($X_{\text{obs}}, y_{\text{obs}}$), and the missing value $y_{\text{mis}}$ is estimated from the regression model $\dot y=\hat\beta_0+X_{\text{mis}}\hat\beta_1$. Where 

* $y$ is assigned as the $n \times1$ vector of the incomplete variable y,
* $y_{\text{obs}}$ is $n_1 \times 1$ vector of observed data,
* $y_{\text{mis}}$ is $n_0 \times 1$ vector of data with missingness,
* $X_{\text{obs}}$ is $n_1 \times q$ matrix of predictors for rows with observed data in $y$,
* $X_{\text{mis}}$ is $n_0 \times q$ matrix of predictors for rows with mising data in $y$. 

However, this imputation method can not be used in multiple imputation, beacuse each imputed dataset produces same estimated values, and the imputed value $\dot y$ cannot reflect the uncertainty of imputation. As an improvement to achieve multiple imputation using linear regression, an appropriate random noise can be added in the regression model $\dot y=\hat\beta_0+X_{\text{mis}}\hat\beta_1+\dot\epsilon$ (Van Buuren, 2012), where the random noise $\dot\epsilon$ is randomly drawn from the normal distribution $N(0,\hat\sigma^2)$, but this method is more suitable for large samples and has limitations in application. 

Bayesian linear regression is more widely applicable in multiple imputation, where the statistical analysis is conducted within the Bayesian inference. We denote the existing sample (such as IDEFICS data) as D, and the real sample as X, and sample D is randomly drawn from sample X. Bayesian inference considers the entire data X distribution with a fixed but unknown probability density function $\mathrm P(X)$ (**Prior**). And core problem of Bayesian inference is to estimate the probability distribution of D based on prior information X, denoted as $\mathrm P(D\mid X)$ (**Posterior**). Bayesian inference is a big topic beyond the scope of this thesis and will not be further expanded here, for more information see "Bayesian Methods for Data Analysis" (Carlin et al., 2008). 

Compared with the general linear regression, which calculates the parameter estimates of existing data set D (e.g., $\hat\beta_0,\hat\beta_1,\hat\sigma$), Bayesian linear regression supplements additional information on the basis of standard linear regression ${\displaystyle Y=\mathbf {X}^{\rm {T}}{\boldsymbol {\beta}}+\varepsilon}$ (e.g., $\boldsymbol {\beta}=(\hat\beta_0,\hat\beta_1)$), it assumes that the data has a specific prior distribution (${\displaystyle \mathrm P ({\boldsymbol {\beta }},\sigma ^{2})}$). The posterior probability distribution of parameters ${\boldsymbol {\beta }}$ and $\sigma$ ($\mathrm P({\boldsymbol {\beta }},\sigma ^{2}\mid \mathbf {y} ,\mathbf {X} )$) is obtained by combining prior beliefs about parameters with the likelihood function of the data ($\mathrm P (\mathbf {y} \mid \mathbf {X} ,{\boldsymbol {\beta}},\sigma ^{2})$) according Bayesian inference, it can be parametrized as
$$\mathrm P({\boldsymbol {\beta }},\sigma ^{2}\mid \mathbf {y} ,\mathbf {X} ) \propto \mathrm P (\mathbf {y} \mid \mathbf {X} ,{\boldsymbol {\beta }},\sigma ^{2}) {\displaystyle \mathrm P ({\boldsymbol {\beta }},\sigma ^{2})}.$$ Bayesian linear regression can incorporate parameter uncertainties, for predictive models $\dot y =\dot\beta_0 + X_{\text{mis}}\dot\beta_1+\dot\epsilon$ ($\dot\epsilon \sim N(0,\dot\sigma^2)$) given the data D, parameters $\dot\beta_0,\dot\beta_1,\dot\sigma$ are randomly obtained from their posterior distribution e.g. $N(\beta_0,\sigma_{\beta_0}^2)$ (Van Buuren, 2012).






## Compatibility and Congeniality

The concepts of compatibility and congeniality introduced in this section refer to the connection between the imputation model and the analysis model (substantive model), they may be beneficial for unbiased estimation in the substantive model (White et al., 2009; Burgess et al., 2013).

The imputation model and substantive model are considered compatible, if

>1. there exists a joint model (e.g. multivariate normal distribution) for a set of density functions ($f_1, f_2, ..., f_n$), and from the joint model the imputations could be drawn,
>2. the imputation model and the substantive model can be expressed as conditional models of the joint model (Liu et al., 2013).

For example, if a joint bivariate normal model $g(x,y|\theta), \theta \in \Theta$ exists, the imputation model to impute $X$ is $f(x|y,\omega),\omega \in \Omega$, and the substantive model is $f(y|x,\phi),\phi \in \Phi$, with the surjective function $f_1:\Theta \rightarrow \Omega$ and $f_2:\Theta \rightarrow \Phi$. The imputation model is compatible with the substantive models, if the two conditional densities $f(x|y,\omega)$ and $f(y|x,\phi)$ use the given densities from the joint model as its conditional density, which means $f(x|y,\omega) = g(x|y,\theta)$ and $f(y|x,\phi) = g(y|x,\theta)$ (Morris et al., 2015).

Compatibility affects the FCS effectiveness (Fully Conditional Specification is also called MICE, detailed introduction in Section 3.5), and it may benefit unbiased parameter estimation. However, the conditional normality of dependent variables $X$ with homoscedasticity is insufficient to justify the linear imputation model for the predictor variable $y$, when only $y$ has missing observations (Morris et al., 2015). The imputation model and the real substantive model may be incompatible when the linear imputation model is assumed for $y$, as a consequence, the imputation model may be misspecified. Furthermore, the compatibility in MICE is easily broken by the categorical variables, interactions, or non-linear terms in the imputation model, which results in the implicitly joint distribution or even not exist. Although parameter estimation may be biased in the substantive model under incompatibility, incompatibility between the analysis model and the imputation model only slightly impacted the final inferences if the imputation model is well specified (Van Buuren, 2012).

In addition to compatibility, there is another important consideration "Congeniality" in multiple imputation presented by Meng (1994), which appoints the required relationship between the analysis model and the imputation model. Congeniality is, essentially, a special case of compatibility, the joint model is the Bayesian joint model $f$. The analysis model and the imputation congenial is congenial if

>1. for incomplete data, mean estimates using the imputation model are asymptotically equal to the posterior predictive mean using the joint model $f$ given missing data, and the associated variance estimates using the imputation model are asymptotically equal to the posterior predictive variance using the joint model $f$ given missing data; 
>2. for observed data, mean estimates using the analysis model are asymptotically equal to the posterior mean from the joint model $f$, and the associated variance estimates using the analysis model are asymptotically equal to the posterior variance from the joint model $f$ (Burgess et al., 2013). 




<!-- An important consideration for a multiple imputation analysis is the congeniality of the models used in imputation and analysis of data. Imputation and analysis models are compatible if a joint model exists under which both models are conditionals [18]. The concept of congeniality, introduced by Meng [13] in the context of multiple imputation, states that as follows: (i) given complete data, the analysis model asymptotically gives the same mean and variance estimates as the posterior mean and variance from a Bayesian joint model, and (ii) given incomplete data, the imputation model gives the same posterior predictive distribution for missing values as the Bayesian joint model. Congeniality is similar to compatibility in a non-Bayesian context with the regularity condition that the priors in the Bayesian model are nonzero over the entire parameter space. -->


If the interaction terms and non-linear relationships do not exist in the imputation model, and the variables are continuous, each univariate imputation model specified as Bayesian linear regression is congenital to the substantive model. Under these circumstances, imputations for variables with missingness are derived independently from the conditional posterior predictive distribution given other variables, and the multiple imputation variance estimates are consistent (Murray, 2018). However, when categorical variables are also included in the imputation model, the analysis model and the imputation model are not congenial, because the relationship between categorical variables and outcome given other variables cannot be linear or log-linear. Specifically, "ISCED" (with levels [1], [2], [3], [4], [5]) is categorical variable with missingness in this thesis, and outcome "log.waist" is continuous, if the imputation models are specified as Bayesian linear regression, the imputation model for "ISCED" is
$$Y_\text{isced} = \beta_0 + \beta_1X_\text{age} + \beta_2X_\text{bmi} + \beta_3X_\text{sex} + \beta_4X_\text{log.waist} + \epsilon.$$
The imputed values are not only limited to 1, 2, 3, 4, 5, other unreasonable results like 4.5 could also appear, which leads to senseless imputation. Therefore, in this case, Bayesian linear regression is misspecified (White, 2009). 

Alternatively, there are two ways to deal with categorical variables. By default, logistic regression is specified as the imputation model in $R$ package $mice$ for binary variables and proportional odds model for ordered categorical variables, there are no meaningless imputed values such as 4.5 for the categorical variable "ISCED" when using them. Notwithstanding, the imputation model using the logistic regression model or proportional odds model is not congenital to the analysis models. As another option, predictive mean matching (PMM) may be an option for the imputation model. Although PMM is not congenital, the first step of PMM is based on a congenital Bayesian linear model, and the missing data are imputed using the observed donors, which also avoids meaningless imputed values. PMM is a compromise method, because the Bayesian linear regression is actually used first, and then in the next step it adjusts the imputed values from the observed values instead of directly drawing from the linear regression (MICE PMM algorithm described in Section 3.6).











## Joint modeling versus fully conditional specification


This section introduces two main methods of performing multiple imputation: Joint Modeling (JM) and Fully Conditional Specification (FCS). 

**1.Multiple Imputation by Joint Modeling**

Joint Modeling (JM) specifies a multivariate distribution for variables with missing conditional on the observed data (Salfrán Vaquero, 2018),  and imputations are randomly drawn from the conditional multivariate distribution by Markov chain Monte Carlo (Schafer, 1997). The joint multivariate normal distribution (Kropko et al., 2017) is the most commonly used assumption. For instance, the multivariate normal distribution for k-dimensional random vector ${\displaystyle \mathbf {X} =(X_{1},\ldots ,X_{k})^{\mathrm {T} }}$ is denoted as
$${\displaystyle \mathbf {X} \ \sim \ {\mathcal {N}}({\boldsymbol {\mu }},\,{\boldsymbol {\Sigma }}).}$$ 

In the multiple imputation, the imputation model and the analysis model are compatible if the two models are conditionally drawn from a joint multivariate normal distribution. When the sample size is relatively large, even for non-normal data the inferences generated under the multivariate normal model are robust (Schafer, 1997). However, JM lacks flexibility in complex data sets in practical applications. For example, when there are outliers or skews in the data, the normality assumption can not be satisfied (He et al., 2009). Secondly, when there are interactions and nonlinear relationships in the analysis model, the imputation model of incomplete variable conditional on the other variables from the analysis model has no conditional normal distribution, the joint multivariate normal distribution does not exist (Katherine et al., 2010). When the data do not conform to the multivariate normal distribution, the estimation is biased. Although interaction terms or nonlinear terms can be regarded as just another variable (JAV) so that the missing data could be imputed under the joint multivariate normal distribution, only under MCAR and using linear regression as the analysis model could the consistent estimation be obtained, inferences under the MAR were biased (Seaman et al., 2012).
 


**2.Multiple Imputation by Fully Conditional Specification (MICE)**

Multiple imputation by Fully Conditional Specification (FCS) is an iterative procedure, it also called Multiple Imputation by Chained Equations (MICE) (Van Buuren et al., 2006). FCS specifies an imputation model for each incomplete variable given other variables and formulates the posterior parameter distribution for the given model. Finally, imputed values for each variable are iteratively created until the imputation converges. Algorithm 2 (Table 5) introduces the MICE process (taking imputation of the variable "age" using Bayesian linear regression as an example).


| |                       Algorithm 2: MICE (FCS)                                         |
|-|---------------------------------------------------------------------------------------|
|1.|The missing data $Y_{\text{mis}}(\text{age})$ is filled using values randomly drawn from the observed $Y_{\text{obs}}(\text{age})$|
|2.|For $i=1,...,p$ in $Y_{\text{mis}}(\text{isced})$, parameter $\Theta_i^* (\beta_{0i}^*,\beta_{1i}^*,\beta_{2i}^*,\beta_{3i}^*,\beta_{4i}^*)$ is randomly drawn from the posterior distribution.|
|3.|$Y_i^*(\text{age})$ is imputed from the conditional imputation model given other variables $f_i(Y_i |Y_{i^-}, \Theta_i^*)$, where $Y_i^*(\text{age}) = \beta_{0i}^* + \beta_{1i}^*X_i(\text{isced}) + \beta_{2i}^*X_i(\text{bmi}) + \beta_{3i}^*X_i(\text{sex}) + \beta_{4i}^*X_i(\text{log.waist}) + \epsilon.$|
|4.|Steps 2-3 are Repeated $m$ times to allow the Markov chain to reach convergence and finally $m$ imputed datasets are generated.|
Table:\centering Algorithm 2: MICE (FCS)

Compared with JM, FCS is more flexible. FCS directly specifies the conditional distribution for each variable and it avoids specifying a multivariate model for the entire data like JM. As another advantage, FCS can deal with different variable types, because each variable can be imputed using a customized imputation model (Bartlett et al., 2015). For instance, linear regression could be used for continuous variables; binary variables can be modeled by logistic regression; predictive mean matching (PMM) applies to any variable type, which was specified as the parametric MICE method in this thesis. However, it is important to correctly specify the imputation model to get the unbiased estimation (Van Buuren, 2012). In this thesis, two different MICE methods were explored: the parametric MICE using Predictive Mean Matching (MICE PMM) compared to the non-parametric approach of random forest MICE (MICE RF) under FCS frameworks, MICE PMM was realized by specifying method "pmm" in R package mice written by Van Buuren (2012), and MICE RF was conducted by calling the R package $\text{CALIBERrfimpute}$ written by Shah et al. (2014).


 


















## Parametric MICE using predictive mean matching

The predictive mean matching (PMM), proposed by Rubin (1986) and Little (1988), is a hot deck imputation method, where the missing value is imputed with a similarly observed observation. Compared with the standard imputation method linear regression, the imputed values produced by PMM is more real. PMM can avoid strong parametric assumptions and can be easily applied to various variable types. If the variable is categorical, the imputed values are also categorical. If the variable is continuous, the imputed values are also continuous. They do not exceed the boundary of the original variable, and the distribution of imputed values is consistent with the original variable. Table 6 details the PMM MICE algorithm in this thesis (take the example of imputing variable "ISCED"):

| |                       Algorithm 3: MICE PMM                                           |
|-|---------------------------------------------------------------------------------------|
|1.|Coefficient $\mathbf{\hat\beta}$ is estimated using Bayesian linear regression given other variables ${\displaystyle Y_{\text{isced}}=\beta_0 + {\beta_{\text{1}}}\mathbf{x_{\text{age}}}+ {\beta_{\text{2}}} \mathbf{x_{\text{sex}}}+ {\beta_{\text{3}}}\mathbf{x_{\text{bmi}}}+ {\beta_{\text{4}}}\mathbf{x_{\text{log.waist}}}+ \varepsilon}$, expressed as ${\displaystyle Y_{\text{isced}}=\mathbf{x}{\mathbf{\beta}}+\varepsilon}$.|
|2.|Parameter $\mathbf{\dot\beta}$ is randomly drawn from its posterior multivariate normal distribution $N(\hat\beta,\text{Var}(\hat\beta))$.|
|3.|For each missing data of variable $Y_{\text{isced}}$, the predicted values $y_i$ are generated using parameter $\dot\beta$, ${\displaystyle \dot y_{i}=\mathbf {x_i}{\dot\beta}+\varepsilon}$.|
|4.|For the observed data of variable $Y_{\text{isced}}$, the distance $d_{\text{PMM}}$ is calculated between all observed case $(x_{i'},y_{i'})$ and each missing case using parameter $\dot\beta$, where $d_{\text{PMM}}=|\mathbf {x_i}{\dot\beta}-\mathbf {x_{i'}}{\dot\beta}|$|
|5.|Sort $d_{\text{PMM}}$ and create a set of $k$ donors with smallest distances from the observed data for each missing case, which means the predicted values with observed data are close to predicted value with missing data.|
|6.|From those $k$ donors, randomly select one and assign its observation value $\displaystyle \dot y_{i'}$ to impute the missing value, where $\displaystyle \dot y_{i}=\displaystyle \dot y_{i'}$.|
|7.|Repeat steps 2 to 6 $m$ times for multiple imputations to generate $m$ imputed datasets.|
Table:\centering Algorithm 3: MICE PMM


 










## MICE using random forest

This section focuses on random forest. First, random forest and its basic unit decision tree are introduced, and then the random forest MICE algorithms are presented.

The decision tree model is a tree structure used for classification and regression. It has two types, classification and regression tree (CART). As the most intuitive difference, regression trees are applied to predict continuous variables, while classification trees are suitable for categorical variables. Generally, a decision tree comprises a root, several internal decision nodes (logical operations), and some leaves (results). The decision process starts from the root, after comparing the data to be tested with the characteristic decision nodes, then selects the next comparison branch according to the comparison result until the leaf is used as the final decision result. Figure 4 demonstrated a simplified example of the decision tree structure for continuous variables.


\begin{center}
\includegraphics[width=4in]{Fotos/decision-tree.png}
\begin{figure}[!h]
\caption{Example of a regression tree}
\end{figure}
\end{center}

Classification and regression trees (CART) could be implemented in MICE (Burgette et al., 2010), and it is shown in Algorithm 4 (denoted as MICE CART, Table 7). $y$ is assigned as the incomplete variable, $y_{\text{obs}}$ is the observed data and $y_{\text{mis}}$ is missing. $X_{\text{obs}}$ the predictor variables $x_1,...,x_k$ for rows with observed data in $y$,  $X_{\text{mis}}$ is for rows with mising data in $y$. 



| |                       Algorithm 4: MICE CART                                          |
|-|---------------------------------------------------------------------------------------|
|1.|The bootstrap sample {$\dot y_{\text{obs}},\dot X_{\text{obs}}$} with sample size $n_{\text{obs}}$ is drawn from {$y_{\text{obs}},X_{\text{obs}}$}.|
|2.|$\dot y_{\text{obs}}$ is fitted by the decision tree $T(X)$ restricted to $\dot X_{\text{obs}}$.|
|3.|Each missing data $y_j^{\text{mis}}$, $j=1,...,n_{\text{mis}}$ in $y_{\text{mis}}$ is predicted using the tree model $T(X_j)$, a series of donors $D_j$ are generated, where $D_j=\{ y^{\text{obs}}_{ij} \mid T(X^{\text{obs}}_{ij})= T(y_j^{\text{mis}}) , i=1,...,n_{\text{obs}} \}$.|
|4.|The missing data $y_j^{\text{mis}}$ is imputed by $\hat y_j^{\text{mis}}$, where $\hat y_j^{\text{mis}}$ is randomly drawn from the donors $D_j$.|
|5.|The steps 1-4 are repeated $m$ times to generate $m$ imputed datasets.|
Table:\centering Algorithm 4: MICE CART



The MICE CART algorithm is similar to MICE PMM, the difference is that the tree model calculates the predictive mean using CART while using PMM is calculated by the regression model. However, MICE CART may overreact to small changes in the data and tend to overfit the model. And using only one decision tree does not consider the uncertainty of decision tree node construction (Bartlett, 2014). Although the bias in the estimation using MICE CART is smaller than the standard MICE based on the linear model, it may result in poor confidence interval coverage (Burgette et al., 2010). In order to improve the predictive ability of the tree model, random forest (RF) can be used to build multiple trees and averages the results of many decision trees to reduce the variance and recurrence of unstable trees (Doove et al., 2014).

Random forest is a classifier that uses multiple decision trees to train and predict; it can handle either discrete or continuous variables. Random forest uses a random way to build a forest, each tree is created using a different sample (bootstrap) and there is no dependence between each decision tree. After building a forest, when the new input sample enters, for categorical variables, each classification tree in the forest makes a decision which category this sample should belong to, and then which category is the most selected is predicted as the category of the sample; For continuous variables, each regression tree splits the input sample at nodes and predicts the results individually (See Figure 4), then the results from regression trees in the random forest are averaged to a final prediction. Figure 5 showed a simplified example of the random forest for categorical variables, and the final class was predicted to be "Class B".


\begin{center}
\includegraphics[width=3.5 in]{Fotos/random-forest.png}
\begin{figure}[!h]
\caption{Example of random forest for categorical variables}
\end{figure}
\end{center}


Random forest uses two methods in the model building process to improve the model's predictive ability. The first method is bootstrap aggregating or bagging (James et al., 2014), which means that random sampling of the data set with a sample size of 2/3 for all observations is used to establish an independent tree. And the remaining 1/3 is called out-of-bag data. This process is repeated dozens or hundreds of times to construct a random forest, where each tree makes independent predictions. Each tree in the random forest is allowed to grow without any pruning, which means that an individual tree's variance may be large. But in the end, by averaging all trees' prediction results, the variance can be reduced without increasing the bias. Secondly, not all $m$ predictors are considered for splitting at each node, the number of input features $p$ is less than the total features of the model $p \le m$. The advantage is to reduce the impact of highly correlated predictive features on the model (Bartlett, 2014), decrease the correlation between bootstrapped trees.

Same to CART, random forest can also perform multiple imputation under the FCS framework. Algorithm 5 in Table 8 introduces the Random Forest MICE algorithm proposed by Doove et al. (2014). Compared to MICE CART, Random Forest MICE used $B$ bootstrapped datasets and builts $B$ trees in a random forest. However, the final predictive result from the random forest is not based on the average tree. It is randomly selected from the predictions in the random forest (donors). For continuous variables, the donors are fitted using regression trees; for categorical variables, the donors are estimated using classification trees.


| |                            Algorithm 5: Random Forest MICE                            |
|-|---------------------------------------------------------------------------------------|
|1.|The $B$ bootstrap datasets {$\dot y_b^{\text{obs}},\dot X_b^{\text{obs}}$}, $\mathrm{b}=1,...,B$ with sample size $n_{\text{obs}}$ is drawn from {$y_{\text{obs}},X_{\text{obs}}$}, and $m_{\text{total}}$ is used to denote the number of total features in model.|
|2.|$\dot y_b^{\text{obs}}$ is fitted by the decision tree $T_b(X)$ restricted to $\dot X_b^{\text{obs}}$, the number of input features $m_b$ in each tree is used to build the decision tree, where $m_b$ is smaller than $m_{\text{total}}$.|
|3.|Like the CART algorithm, the decision tree model $T_b(X)$ is used to predict the missing data $y^{\text{mis}}$ as the imputations, and the final prediction using random forest ${\displaystyle {\hat {T({y_\text{mis}})}}}$ is randomly chosen from a set of $B$ donors $T_b(y_b^{\text{mis}})$, out-of-bag error ${\displaystyle \sigma ={\sqrt {\frac {\sum _{b=1}^{B}(T_b(y_b^{\text{mis}})-\hat {T({y_\text{mis}})})^{2}}{B-1}}}}$ is calculated for imputations.|
|4.|The steps 1-3 are repeated $m$ times to generate $m$ imputed datasets.|
Table:\centering Algorithm 5: Random Forest MICE

 
In this thesis, random forest MICE was implemented using the approach proposed by Shah et al. (2014), which was carried out in the $R$ package $\text{CALIBERrfimpute}$. In order to distinguish Random Forest MICE in Algorithm 5, this algorithm is called MICE RF (Algorithm 6 in Table 9). For categorical variables, MICE RF uses the same method as Random Forest MICE; each imputed value is randomly selected from the predictions using classification trees in the random forest. For continuous variables, MICE RF assumes that the predictions using random forest meet the conditional normality and constant variance. Each imputed value is randomly selected from a normal distribution given the conditional mean of predictions using random forest. The algorithm has been tested using survival analysis on simulated data and real data under MCAR and MAR. Compared with the polytomous regression, the hazard ratios were slightly bias, but the confidence interval coverage was correct (Shah et al., 2014).


| |                            Algorithm: MICE RF                                         |
|-|---------------------------------------------------------------------------------------|
|1.|The $B$ bootstrap datasets {$\dot y_b^{\text{obs}},\dot X_b^{\text{obs}}$}, $\mathrm{b}=1,...,B$ with sample size $n_{\text{obs}}$ is drawn from {$y_{\text{obs}},X_{\text{obs}}$}, and $m_{\text{total}}$ is used to denote the number of total features in model.|
|2.|$\dot y_b^{\text{obs}}$ is fitted by the decision tree $T_b(X)$ restricted to $\dot X_b^{\text{obs}}$, the number of input features $m_b$ in each tree is used to build the decision tree, where $m_b$ is smaller than $m_{\text{total}}$.|
|3.|The decision tree model $T_b(X)$ is used to predict the missing data $y^{\text{mis}}$, the imputed value is randomly drawn from the the normal distribution $N(\mu_{T}, \sigma_T)$, where the mean $\mu_t={\frac{1}{B}} \sum_{b=1}^{B} T_b(y_b^{\text{mis}})$, the variance $\sigma_T$ is out-of-bag error $\sigma_T ={\sqrt {\frac {\sum_{b=1}^{B}(T_b(y_b^{\text{mis}})-\hat {T({y_\text{mis}})})^{2}}{B-1}}}$.|
|4.|The steps 1-3 are repeated $m$ times to generate $m$ imputed datasets.|
Table:\centering Algorithm 6: MICE RF







  
# Simulation study

This thesis compared parametric MICE using Predictive Mean Matching (MICE PMM) to the non-parametric approach of random forest MICE (MICE RF) with respect to the following three aspects:

>1. The impact of number of trees on MICE RF
>2. The impacts of sample size and missing ratio on MICE PMM and MICE RF
>3. The impact of interaction and non-linearity in the imputation model on the performance of MICE PMM and MICE RF

This chapter first introduces how to generate a simulation Dataset C with missing under MAR, then presents the research motivations and simulation methods of each Setting, and finally shows how to compare the performance of two MICEs using linear regression and conditional independence test (focusing on Fisher's z-test).






## Data generation
 
Of the three settings, each setting requires 1000 simulations, the 1000 datasets (Datasets C) were obtained by randomly sampling from Dataset B, which was completely observed in IDEFICS data. In Setting 1 and Setting 3, the sample size of each dataset was 2000, the 20% missing values in 3 variables ("age", "BMI", "ISCED") were artificially created based on the MAR. It should be noted here that in Setting 2 the sample size was changed to 200 or 1000 and the missing ratio was changed to 5% or 20%. The missing generation process used the $ampute$ function in the $R$ package $mice$ (Schouten et al., 2018), and Figure 6 illustrates the $ampute$ process.

\begin{center}
\includegraphics[width=6in]{Fotos/Ampute.png}
\begin{figure}[!h]
\caption{The ampute procedure to generate Dataset C}
\end{figure}
\end{center}

When generating missing values under MAR, this thesis considered all 7 missing patterns of three variables "age", "bmi" and "ISCED", i.e. only one variable was missing, two variables were missing, and three variables were missing. Table 10 shows the 7 missing patterns, where 1 means that the variable is completely observed, and 0 means the incomplete variable. Figure 7 illustrates the corresponding missing patterns generated by using $ampute$ under MAR, where the first row refers to the complete case (pattern 1, 1, 1, 1, 1), and the remaining 7 rows represent 7 missing patterns. Red squares indicate missing variables, blue squares indicate complete variables, the numbers in the left column indicate the number of observations in this pattern. E.g. the last row (pattern 1, 1, 0, 0, 0) means that in 51 observations all three variables were missing.

------------------------------------------------------
 missing patter   sex   log.waist   age   isced   bmi   
---------------- ----- ----------- ----- ------- -----
        1          1        1        1      1      0     
        
        2          1        1        1      0      1   
        
        3          1        1        1      0      0   
        
        4          1        1        0      1      1     

        5          1        1        0      1      0     

        6          1        1        0      0      1     
  
        7          1        1        0      0      0     
-------------------------------------------------------
Table:\centering Missing patterns matrix in simulation study

\begin{center}
\includegraphics[width=3.0in]{Fotos/missing-patter_01.png}
\begin{figure}[!h]
\caption{The missing patterns using ampute}
\end{figure}
\end{center}

As shown in Figure 6, Dataset C (randomly sampled from complete Dataset B) was randomly divided into 7 sub-datasets with similar sample sizes. Each subset generated missing values according to its own missing pattern and weight matrix, and the weight matrix used in this simulation study was the same as the missing pattern matrix (Table 11). The idea of the weight matrix is to weigh the variables differently to make them play different roles in the missing process (Schouten et al., 2018). The higher the variable's weight, the greater the importance of the variable in generating missing values in this missing pattern. This study used a simple case: the weight of the weighted variables was 1, and they were equally important. When the weight of the variable was 0, the value of the variable did not affect missing generating. For instance, when generating missing values according to the missing pattern 1 (only "BMI" missing), the weight of the variable "bmi" under MAR was 0 and other variables were 1, which means the missingness of "BMI" was independent on "BMI" that will be created missing. Correspondingly, if the data is MCAR, the weight matrix is not considered, the missingness of "BMI" is completely random; and the weight of "BMI" could be 1 under MNAR, which means the missingness of "BMI" depends not only on the observed data but also on the missing "BMI".

----------------------------------------------------------------------------------------------
 missing patter   sex ($w_1$)  log.waist ($w_2$)   age ($w_3$)   isced ($w_4$)   bmi ($w_5$)   
---------------- ------------ ------------------- ------------- --------------- --------------
        1              1                1                1              1             0     
          
        2              1                1                1              0             1   
        
        3              1                1                1              0             0   
        
        4              1                1                0              1             1     
  
        5              1                1                0              1             0     

        6              1                1                0              0             1     
  
        7              1                1                0              0             0     
----------------------------------------------------------------------------------------------
Table:\centering Weight matrix in simulation study



After determining the weighting matrix, each observation in each missing pattern was assigned the probability of missing according to the weighted sum score $wss$ and pre-specified missing ratio e.g. 20%. The weighted sum score was using calculated using linear regression equation according to the weighting matrix and each observation values (Schouten et al., 2018),
$$wss_i = w_1 \cdot y_{\text{sex}_i} + w_2 \cdot y_{\text{log.waist}_i}+ w_3 \cdot y_{\text{age}_i} + w_4 \cdot y_{\text{isced}_i}+w_5 \cdot y_{\text{bmi}_i},$$
where $\{w_1,w_2,w_3,w_4,w_5\}$ are corresponding weights in Table 11 and $\{y_{\text{sex}_i},y_{\text{log.waist}_i},y_{\text{age}_i},y_{\text{isced}_i}$, $y_{\text{bmi}_i}\}$ are the values of observation $i$ in each missing pattern. When the weighted sum score was higher, the observation had a higher probability of generating missing values according to the missing pattern. Finally, the 7 candidate sub-datasets generated missing subsets and completed subsets according to the missing patterns. These data sets were aggregated into the final simulation Dataset C with missing values.











## The settings of simulation study

This section introduces the three simulation settings of this thesis, the impact of number of trees on MICE RF, the impacts of sample size and missing ratio on MICE PMM and MICE RF, and the impact of interaction and non-linearity in the imputation model on MICE PMM and MICE RF. Under each setting, the 1000 simulation Datasets C generated under MAR (Section 4.1) were imputed using MICE PMM (Section 3.6 Algorithm 3) and MICE RF (Section 3.7 Algorithm 6). The imputed datasets were analyzed using linear regression and conditional independence test (focusing on Fisher's z-test) described in Section 4.3.


The choice of the imputation model and analysis model is the key to implement MICE. Here, the imputation models and analysis models in the three settings are stated. When using linear regression to compare the performance of MICE PMM and MICE RF, the analysis model did not change with the imputation model. In any setting, the analysis model was
$$\text{log.waist} =  \text{sex + age + bmi + isced} + \text{sex.age + age.bmi}.$$
Regarding the imputation model, the accepted recommendation is that any effects in the final analysis model, including interactions and non-linear terms, should be included in the imputation model for parametric MICE (Schafer et al., 1998). When using the non-parametric method MICE RF, Random Forest can automatically adapt to interactions and nonlinear effects between variables, so there is no need to specify in the imputation model (Shah et al., 2014). In this study, Setting 1 and Setting 2 ignored the interactions and nonlinear relationships in the imputation model, whether MICE PMM or MICE RF, the applied imputation model was ($\text{sex, age, bmi, isced, log.waist}$). Setting 3 aimed to explore the impact of including interactions and nonlinear relationships in the imputation model on MICE PMM and MICE RF. For MICE PMM, not only all the main 5 variables and two interactions "sex.age", "age.bmi" in the analysis model were included in the imputation model, all other 8 two-way interactions and 3 quadratic terms of continuous variables were also considered, and the final imputation model was ($\text{sex, age, bmi, isced, log.waist}$, $\text{age:sex}$, $\text{age:bmi}$, $\text{age:isced}$, $\text{age:log.waist}$, $\text{sex:bmi}$, $\text{sex:isced}$, $\text{sex:log.waist}$, $\text{bmi:isced}$, $\text{bmi:log.waist}$, $\text{isced:log.waist}$, $\text{age}^2$, $\text{bmi}^2$, $\text{log.waist}^2$). 





### Setting 1: The tree number on MICE RF
 
Random forests construct a large number of trees by using bagging and random picking sample of features, by averaging the results of many decision trees, the uncertainty of estimation can be decreased (Doove et al., 2014). For categorical variables with many categories, if there are only fewer trees in the random forest, some categories could be predicted only once or not at all, which may reduced predictive power in the random forest. Although a large number of trees in the random forest may provide higher preciseness and more robust imputation results, it can increase the calculation burden, and the computational time is almost linearly related to the number of trees. Reducing the trees' number growing in forests could adequately accelerate the calculation, nonetheless, when the trees in the random forest are very thin, the prediction results are biased (Stekhoven et al., 2012). 

For continuous variables, it has been demonstrated that the confidence interval of estimators using MICE RF with 100 trees was slightly narrower than 10 trees, but with larger bias, and for categorical variables, MICE RF with 10 trees and 100 trees produced almost similar results (Shah et al., 2014). Based on the above conclusions, it is interesting to see whether the number of trees in the random forest affects the performance of MICE RF based on IDEFICS data. Here, Setting 1 compared the following 4 "patterns":

>* **Full data** (The complete Dataset C with n=2000 was used for analysis.)
>* **Parametric MICE PMM** (The 20% of missing values in the complete Dataset C were created, and imputation was conducted using Algorithm 3 described in Section 3.6.)
>* **MICE RF with 10 trees** (The 20% of missing values in the complete Dataset C were created, and imputation was conducted using Algorithm 6 described in Section 3.7 with 10 trees in the random forest.)
>* **MICE RF with 100 trees** (The 20% of missing values in the complete Dataset C were created, and imputation was conducted using Algorithm 6 described in Section 3.7 with 100 trees in the random forest.)



### Setting 2: The sample size and missing ratio on MICE PMM and MICE RF

The sample size and the proportion of missing values may affect the parametric MICE results. It has been proved in simulation studies that a small (<5%) amount of missing data commonly did not result in relevant percipience loss or serious bias when using parametric MICE. However, when the missing ratio was higher than 50%, the regression coefficient estimators were biased regardless of MCAR or MAR missing mechanisms (Marshall et al., 2010). And for MICE PMM, when the missing proportion is too high or the sample size is too small, there may be only a small number of non-missing donors available. As a result, multiple duplicate donors appear in the imputed dataset and estimation may be biased (Van Buuren, 2012).
 
As a non-parametric approach, the random forest may also be sensitive to changes in sample size. Tang et al. (2017) investigated whether the relative imputation error improved with the increase of sample size 100, 200, 500, 1000, and 2000 by using different random forest imputation methods (Ishwaran et al., 2008; Stekhoven et al., 2013), and the standard deviation and the mean relative imputation error increased with increasing sample size. However, Slade et al. (2020) compared the tree-based MICE methods (single tree and random forest) and parametric MICE methods. They concluded in the study that the relative performance of the MICEs did not change with the sample size in the range of 100-1000. In Setting 2, this study further investigated the impact of sample size and missing rate under the following 4 combinations on the performance of MICE PMM and MICE RF based on IDEFICS data, 

>* Sample size $n=200\;\;$ and missing ratio p=5%
>* Sample size $n=200\;\;$ and missing ratio p=20%
>* Sample size $n=1000$ and missing ratio p=5%
>* Sample size $n=1000$ and missing ratio p=20%

Under each combination of sample size and missing ratio, the following 3 "patterns" were compared.

>* **Full data** (The complete Dataset C with n=200 or n=1000 was used for analysis.)
>* **MICE PMM** (The 5% or 20% of missing values in the complete Dataset C were created, and parametric MICE PMM was conducted using Algorithm 3 described in Section 3.6.)
>* **MICE RF** (The 5% or 20% of missing values in the complete Dataset C were created, and non-parametric MICE was conducted using Algorithm 6 described in Section 3.7 with 10 trees in the random forest.)







### Setting 3: The impact of interaction and non-linearity in the imputation model on the performance of MICE PMM and MICE RF

Random forest is a very flexible non-parametric method, it does not rely on parametric distributional assumptions, and it is insensitive to interactions and high correlations between predictors. When the random forest is used within the MICE framework, the imputation model can adapt interactions or other nonlinearities between variables without specification, which avoids the risk of incorrectly specifying the imputation model in the parametric MICE. Therefore, the performance using random-forest-based MICE may be superior to the parametric MICE in terms of bias and coverage when interactions or other nonlinear effects are incorporated in the imputation model.

As for the parameter MICE, when the interaction terms are zero, excluding interaction in the imputation model can still obtain unbiased estimators and high confidence interval coverage. However, when the interaction terms are not zero, excluding them from the imputation model may lead to biased estimators and insufficient coverage (Tilling et al., 2016). Therefore, only when the imputation model of parametric MICE contains correct interactions and is specified correctly, parametric MICE may obtain better performance (Slade et al., 2020). In Setting 1 and Setting 2, the imputation model of parametric MICE PMM did not contain any interaction and non-linear relationship (MICE PMM 2); In contrast, Setting 3 included all two-way interaction terms and 3 quadratic terms of continuous variables when using MICE PMM (MICE PMM 1). The following 4 "patterns" were compared in Setting 3.

>* **Full data** (The complete Dataset C with n=2000 was used for analysis.)
>* **MICE RF** (The 20% of missing values in the complete Dataset C were created, and imputation was conducted using Algorithm 6 described in section 3.7 with 10 trees in the random forest.)
>* **MICE PMM 1** (The 20% of missing values in the complete Dataset C were created, and imputation was conducted using Algorithm 3 described in section 3.6, the imputation model was ($\text{sex, age, bmi, isced, log.waist}$, $\text{age:sex}$, $\text{age:bmi}$, $\text{age:isced}$, $\text{age:log.waist}$, $\text{sex:bmi}$, $\text{sex:isced}$, $\text{sex:log.waist}$, $\text{bmi:isced}$, $\text{bmi:log.waist}$, $\text{isced:log.waist}$, $\text{age}^2$, $\text{bmi}^2$, $\text{log.waist}^2$).)
>* **MICE PMM 2** (Same as Setting 1, the 20% of missing values in the complete Dataset C were created, and imputation was conducted using Algorithm 3 described in section 3.6, the imputation model was ($\text{sex, age, bmi, isced, log.waist}$).)


In addition, the imputation methods using MICE PMM 1 for 10 interaction terms $\text{age:sex}$, $\text{age:bmi}$, $\text{age:isced}$, $\text{age:log.waist}$, $\text{sex:bmi}$, $\text{sex:isced}$, $\text{sex:log.waist}$, $\text{bmi:isced}$, $\text{bmi:log.waist}$, $\text{isced:log.waist}$ and 3 the nonlinear quadratic terms $\text{age}^2$, $\text{bmi}^2$, $\text{log.waist}^2$ were passive imputation, which is called "impute then transform" proposed by Hippel (2009). As an example to impute the interaction $\text{age:bmi}$, first the components $\text{age}$, $\text{bmi}$ were imputed, then $\text{sex.age}$ was created. Since the prediction matrix is too large in the form of a table, it is shown in Figure 8 (read from left to right). E.g., when the variable $\text{isced}$ was imputed (See the fourth row in Figure 8), not only the variables "age", "sex", "BMI", "log.waist", but all two-way interaction terms and 3 quadratic terms were also used as a predictor
$Y(\text{isced}) = \beta_{0} + \beta_{1}X(\text{age}) + \beta_{2}X(\text{sex}) + \beta_{3}X(\text{bmi}) + \beta_{4}X(\text{log.waist}) + \beta_{5}X(\text{age:sex}) + \beta_{6}X(\text{age.bmi}) + \beta_{7}X(\text{age.isced}) + \beta_{8}X(\text{age.log.waist}) + \beta_{9}X(\text{sex:bmi}) + \beta_{10}X(\text{sex:isced}) + \beta_{11}X(\text{sex:log.waist}) + \beta_{12}X(\text{bmi:isced}) + \beta_{13}X(\text{bmi:log.waist})$ + $\beta_{14}X(\text{isced:log.waist}) + \beta_{15}X(\text{age}^2) + \beta_{16}X(\text{bmi}^2) + \beta_{17}X(\text{log.waist}^2)+ \epsilon.$



\begin{center}
\includegraphics[width=6.2in]{Fotos/predictmatrix.png}
\begin{figure}[!h]
\caption{Prediction matrix using MICE PMM in Setting 3}
\end{figure}
\end{center}




## Analyse and compare

This section introduces analysis methods after generating imputed datasets using MICE PMM and MICE RF. In this thesis, two methods of linear regression and conditional independence test (focusing on Fisher's z-test) were used to analyze the imputed datasets to evaluate and compare the performance of MICE PMM and MICE RF.



### Estimators performance using linear regression

After imputation using MICE PMM and MICE RF, the performance of estimators was first analyzed using linear regression (See Algorithm 7 in Table 12). The final analysis model should be correctly specified and fitted, in this study, regardless of the setting, the analysis model is
$$\text{log.waist} =  \text{sex + age + bmi + isced} + \text{sex.age + age.bmi}.$$
For each setting and each pattern, the 1000 results were generated using the analysis model, then these results were combined using Rubin's rule, a set of coefficient estimates and 95% CIs were obtained. The analysis results based on the complete Dataset B in Table 3 were considered as true values, which could assess the bias and CIs based on 1000 datasets. For each coefficient, the Monte Carlo bias was calculated as the mean of the difference between the estimated coefficient ($E_{1i}$) and the true consistent coefficient drawn from Dataset B ($E_{0i}$) in the following way: 
$$\text{Bias}=\frac{\sum_{i=1}^{1000}  (E_{1i}-E_{0i}) }{1000}.$$
The Bias was not directly used for performance comparison between MICE RF or MICE PMM, but the converted z-score was applied. Firstly, the standard deviation difference between the estimator and the true value was defined as $${\displaystyle \text{SD}={\sqrt {{\frac {1}{1000-1}}\sum _{i=1}^{1000}\left(\text{Bias}-{ (E_{1i}-E_{0i})}\right)^{2}}},}$$ then the z-score was calculated using Bias divided by SD 
$$\text{Z-Score} = \frac {\text{Bias}}{\text{SD}}.$$
The actual confidence interval coverage (CI coverage) was also one of the indicators that measured the performance of MICE RF and MICE PMM, the nominal CI coverage is 95%. In 1000 simulations for each setting, if the estimated 95% $\text{CI}_i$ did not contain the true value (Table 3), then the coverage was 0, assuming that there were $C_1$ times of 1000 simulations. If the estimated interval contained the true value, then the coverage was 1, assuming that there were $c$ times that the $\text{CI}_i$ included the true value. The CI coverage was defined as
$$\text{CI Coverage} = c/1000.$$
The confidence interval length $\text{CL}_i$ refers to the estimated 95% CI width of each coefficient and each simulation. 
The average confidence interval length (CI Length) was defined as the average of all 95% confidence interval widths $\text{CL}_1, \text{CL}_2, ... , \text{CL}_{1000}$ of each coefficient. The method with smaller CI Length is generally considered as good. 
$$\text{CI Length}=\frac{\sum_{i=1}^{1000}\text{CL}_i}{1000}.$$



| |          Algorithm 7: Simulation using linear regression                              |
|-|---------------------------------------------------------------------------------------|
|1.|Generating simulation dataset, for Setting 1 and Setting 3, the simulation dataset with sample size n=2000 and missing ratio p=20% was produced by using $ampute$; for Setting 2, the sample size was changed to n=200 and n=1000, the missing ratio was changed to p=5% and p=20%.|
|2.|The imputed datasets were generated using MICE PMM and MICE RF based on the simulation dataset.|
|3.|Linear regression model was used to fit the Dataset C (without missing in step 1) and the imputed datasets (in step 2).|
|4.|Steps 1-3 were repeated 1000 times for each setting and the 1000 results were summarized, the Monte Carlo bias (and z-score) of estimators, the actual CI coverage and average CI length were evaluated.|
Table:\centering Algorithm 7: Simulation using linear regression






### Estimators performance using conditional independence test 


In addition to considering the linear regression model, the power and the actual type 1 error of conditional independence test were evaluated based on the Dataset C without missing (Full data), and the imputed datasets using MICE PMM and MICE RF. In the thesis, Fisher's z-test was used to conduct the conditional independence test for continuous variables, which was implemented using the $R$ package $micd$ proposed by Foraita et al. (2020). The Fisher's z-test formulates in the following,
$$\mathrm{Z}=\frac{1}{2}{\sqrt{M-|S|-3}} \ {(\text{ln}\frac{1+R}{1-R})}$$

* $M$ is the sample size.
* $|S|$ is the number of independent given variables.
* $R$ is the partial correlation coefficient of $X_i$ and $X_j$.

The null hypothesis $H_0$ and alternative hypotheses $H_1$ of the Fisher's z-test are formulated as follows:

>$H_0$: the partial correlation between $\text{log.waist}$ and $\text{BMI}$ given $\text{age}$ is zero.    
$H_1$: the partial correlation between $\text{log.waist}$ and $\text{BMI}$ given $\text{age}$ is not zero.
 

**The power of $\mathrm{X}{\perp\!\!\!\perp}\mathrm{Y} | \mathrm{Z}$**
 
The power of $X{\perp\!\!\!\perp}Y | Z$ can be calculated based on the same imputed datasets as linear regression. First, the variable combination of (X, Y, Z) was chosen from imputed datasets, where $X = \text{log.waist}$, $Y = \text{bmi}$, $Z = \text{age}$. Then the Fisher's z-test was implemented on each imputed dataset to test $X{\perp\!\!\!\perp}Y | Z$ (the independence of X and Y given Z). At last, p-values of Fisher's z-test were combined using Rubin’s rules. Given nominal $\alpha$ level 0.05, if the times of accepting $H_1$ in 1000 simulation was $m_2$, the power $1-\beta$ was defined as
$$1-\beta = \frac{m_2}{1000}.$$

**The type I error of $\mathrm{X}{\perp\!\!\!\perp}\mathrm{Y} | \mathrm{Z}$**

In order to test the actual type I error of $X{\perp\!\!\!\perp}Y | Z$, the new datasets were required, where $X$ and $Y$ were conditionally independent given $Z$. First, the new complete Dataset C was resampled and the linear regression $Y_{\text{bmi}}=\beta_0 + \beta_1 X_{\text{age}} + \epsilon$ was performed. Then all observations in variable $Y = \text{bmi}$ were deleted from new Dataset C, and the new variable $Y$ was regenerated using the above linear regression. After creating 20% missing values using the method described in Section 4.1, MICE PMM and MICE RF were conducted. Finally, Fisher's z-test was carried out on the Dataset C and the imputed datasets. Given $\alpha=0.05$, if there were $m_1$ times of 1000 simulation to reject $H_0$, the actual type 1 error $\alpha^*$ was defined as
$$\alpha^*=\frac{m_1}{1000}.$$
The analysis process of the conditional independence test is shown in Algorithm 8 (Table 13).

| |          Algorithm 8: Simulation using conditional independence test                  |
|-|---------------------------------------------------------------------------------------|
|1.|Conditional independence test (focusing on Fisher's z-test) was supplementarily used to evaluate the performance of MICE PMM and MICE RF, the power of conditional independence test can be calculated using the same imputed datasets as linear regression (Algorithm 7).|
|2.|The simulation dataset was regenerated to estimate the actual type 1 error of the Fisher's z-test, where $X = \text{log.waist}$ and $Y = \text{bmi}$ were conditional independent given $Z = \text{age}$.|
|3.|After creating missing, MICE PMM and MICE RF were carried out again based on the regenerated simulation Dataset C, the Fisher's z-test was implemented on the new Dataset C and the imputed datasets.|
|4.|Steps 1-3 were repeated 1000 times for each setting, and the 1000 results were combined to calculate the actual type I error and power.|
Table:\centering Algorithm 8: Simulation using conditional independence test












 


 


# Results

This thesis aims to compare parametric MICE PMM with the non-parametric approach MICE RF in 3 settings. The linear regression and the conditional independence test (concentrating on Fisher's z-test) were used to analyze imputed datasets. The simulation results are demonstrated in the following.



```{r echo=F,message = FALSE, error = FALSE, warning = FALSE}

## Results: Linear Regression Performance
getParameter_lm <- function(method){
  ## draw the coefficient estimators
  estimates <- sapply(results, function(x){
    as.numeric(x[[method]][ , 'est'])
  })
  ## calculate bias of estimators 
  bias <- apply(estimates,1,mean) - coef
  ## calculate the standard error 
  se_bias <- apply(estimates,1,sd) / sqrt(ncol(estimates))
  ## calculate z score
  z <- bias / se_bias
  ## confidence interval length
  ci_len <- apply(sapply(results, function(x){
    as.numeric(x[[method]][ , 'hi 95']) - 
      as.numeric(x[[method]][ , 'lo 95'])
  }),1,mean)
  ## coverage of the unbiased estimates
  ci_cov <- apply(sapply(results, function(x){
    as.numeric(x[[method]][ , 'cover'])
  }),1,mean)
  ## summary the output and rename
  out <- cbind(bias, se_bias, z, ci_len, ci_cov)
  colnames(out) <- c('bias', 'se_bias', 'z_bias', 
                     'ci_len', 'ci_cov')
  out
}

Table_lm <- function(x,n){
  results_lm <- lapply(methods, 
                       function(x){getParameter_lm(x)})
  ## convert list to data.frame
  results_lm <- do.call(rbind.data.frame, results_lm)
  
  ## reorder
  results_lm <- cbind(results_lm, 
                      order1=rep(1:10,time=n),
                      order2=rep(1:n,each=10))
  results_lm <- results_lm[order(results_lm$order1,
                                 results_lm$order2),]
  ## format the names
  results_lm <- cbind(Variables=c('Intercept',rep('',n-1),
                                  'Age',rep('',n-1),
                                  'BMI',rep('',n-1),
                                  'Sex',rep('',n-1),
                                  'ISCED[2]',rep('',n-1),
                                  'ISCED[3]',rep('',n-1),
                                  'ISCED[4]',rep('',n-1),
                                  'ISCED[5]',rep('',n-1),
                                  'Age:Sex',rep('',n-1),
                                  'Age:BMI',rep('',n-1)),
                      Nodell=Model_names,
                      results_lm[,c(1,2,3,4,5)])
  ## format the decimal
  results_lm$bias <- round(results_lm$bias, 4)
  results_lm$se_bias <- round(results_lm$se_bias, 4)
  results_lm$z_bias <- round(results_lm$z_bias, 4)
  results_lm$ci_len <- round(results_lm$ci_len, 4)
  library(formattable)
  results_lm$ci_cov <- percent(results_lm$ci_cov,digits = 1)
  colnames(results_lm) <- c('Variables','Models','Bias', 
                            'SD', 
                            'Z-score', 
                            'CI length', 
                            'CI coverage')
  rownames(results_lm) <- NULL
  return(results_lm)
}


## Results: Conditional Independence Test
getParameter_CIT <- function(method){
  ## draw the coefficient estimates
  Fisher.p <- sapply(results, function(x){
    as.numeric(x[[method]][ , 'Fisher.p'])
  })
  Fisher.p <- Fisher.p[1,]
  cover <- ifelse(Fisher.p <= 0.05,1,0)
  cover_ratio <- mean(cover)
  cover_ratio
}



Table_CIT <- function(x){
  results_CIT <- lapply(methods, 
                        function(x){getParameter_CIT(x)})
  ## convert list to data.frame
  results_CIT <- do.call(rbind.data.frame, results_CIT)
  ## format the names
  results_CIT <- cbind(Modell=Model_names,
                      results_CIT)
  colnames(results_CIT) <- c('Models','Ratio')
  rownames(results_CIT) <- NULL
  ## format the decimal
  library(formattable)
  results_CIT$Ratio <- percent(results_CIT$Ratio,digits = 2)
  return(results_CIT)
}
```


## Results using linear regression

When using linear regression as the analysis method, the bias (z-score), the average length of the confidence interval (CI length), and the actual confidence interval coverage (CI coverage) were used to evaluate the performance using MICE PMM and MICE RF. As described in Section 4.3.1, the bias was the Monte Carlo bias of the estimator of the respective variable coefficient based on 1000 simulations, and the Monte Carlo bias of the estimator was not directly compared, rather the converted z-score was applied, which was calculated using Bias divided by SD defined in Section 4.3.1. 



### Setting 1

The effect of trees number in the random forest on MICE RF is the interest of Setting 1. In the simulation study, it has found that the performance of the parametric MICE PMM was better than MICE RF in general, even for interaction terms (the imputation model of MICE PMM did not include interactions "age:sex" and "age:bmi"). MICE PMM had smaller z-scores, shorter CI lengths and higher CI coverages. The non-parametric method MICE RF also had excellent performance in the categorical variable "ISCED" and interaction term "age:sex", but for continuous variables and interaction term "age:bmi", the z-score was large and the coverage was less than 90%.

Setting 1 compared 4 "patterns" described in Section 4.2.1: Full data (complete Dataset C without missing), MICE RF with 10 trees, MICE RF with 100 trees and parametric MICE PMM. The analysis model $\text{log.waist} =  \text{sex + age + bmi + isced} + \text{sex.age + age.bmi}$ was used in all 4 "patterns", and the imputation model in MICE PMM and MICE RF was ($\text{sex, age, bmi, isced, log.waist}$). The following introduces the specific results (Table 14).


```{r echo=F,message = FALSE, error = FALSE, warning = FALSE}
load("~/Library/Mobile Documents/com~apple~CloudDocs/05. Masterarbeit/04_Masterarbeit/01_Data/01_linear_regression_V03/results_lm_S1.RData")

## results of linear regression performance
data_complete$sex <- as.factor(data_complete$sex)
best.fit <- lm(log.waist ~  age + bmi + sex + isced + sex:age + 
                 age:bmi, data = data_complete)
coef <- summary(best.fit)$coefficients[ ,1]
methods <- c('full', 'rf10', 'rf100', 'micepmm')
Model_names <- rep(c("Full data","RF MICE with 10 trees",
                     "RF MICE with 100 trees","Parametric MICE PMM"),
                   times=10)
results <- results_lm_S1
resultsTable_lm_S1 <- Table_lm(results_lm_S1,4)


S1_Results <- resultsTable_lm_S1[c(5:12,17:40),]
rownames(S1_Results) <- NULL
knitr::kable(S1_Results,
             format  = "pandoc", 
             row.names = NA,
             caption = "The impact of tree number using linear regression")
```


First of all, for continuous variables, the results using MICE PMM in terms of the CI length and CI coverage were better compared with MICE RF, and were closer to Full data analysis, e.g. CI length ("age": Full data 0.0079 vs. MICE PMM 0.0083; "BMI": Full data 0.0715 vs. MICE PMM 0.0770) and CI coverage ("age": Full data 96.8% vs. MICE PMM 96.2%; "BMI": Full data 93.4% vs. MICE PMM 93.7%). Although the z-scores using MICE RF ("age": with 10 trees 45.6981, with 100 trees 33.7897; "BMI": with 10 trees 47.1999, with 100 trees 36.3006) and MICE PMM ("age": 9.8557; "BMI": 9.8597) were larger than Full data ("age": 1.3962; "BMI": 1.1077), MICE PMM was obviously smaller than MICE RF. When comparing the MICE RF with 10 trees and the MICE RF with 100 trees, performance using MICE RF based on 100 trees was better than 10 trees. It can be found that the z-score using 100 trees was relative smaller, and it had narrower CI length ("age": 0.0095 vs. 0.0092; "BMI": 0.0907 vs. 0.0874) and higher CI coverage ("age": 84.8% vs 90.3%; "BMI": 76.6% vs. 83.5%). 

However, it can also be seen from the results in Table 14 that the z-scores of "BMI" and the interaction item "age:BMI" when using MICE RFs were large, and the CI coverages were poor (less than 85%). In order to explore this phenomenon, stripplots in Figure 8 were used to diagnose and compare the imputed datasets generated using MICE PMM and MICE RFs, the distribution of the imputed values (red circles) and the observed values (blue circles) for variables "age" and "BMI" were compared. The Y-axis of each subplot represents the value range of its variables. On the X-axis of each subplot, "0" means the Dataset C with missing (all circles are blue circles), and "1"-"10" means 10 imputed datasets generated at each MICE procedure (on the blue circles, the red circle is the imputed value). It is obvious that there were some large imputed values for "BMI" and "age" when using MICE RF. From Figure 9 we can see that the variable "age" was between 2-10, when the number of trees in the random forest increased, there were decreased imputed values outside this range, which may result in better performance for MICE RF with 100 trees. However, some imputed values of "BMI" using MICE RFs were unplausible. Because the variable "BMI" used in this thesis was converted BMI percent between 0 and 1 (Cole et al., 2012), but some imputed values were greater than 1 even negative. It can also explain the poor performance of MICE RFs for "BMI". And due to the poor performance of "BMI" and "age", it may further lead to the poor estimation for interaction "age:BMI". Besides, it was best not to impute the transformed variable rather than to impute its component variables (Van Buuren, 2012). For example, height and weight should be imputed, and then converted to BMI percent according to Cole et al. (2012) after imputation, which may reduce bias and produce a better performance.
 

\begin{center}
\includegraphics[width=6.5in]{Fotos/Stripplot.jpg}
\begin{figure}[!h]
\caption{Stripplots for variables "age" and "BMI"}
\end{figure}
\end{center}

Secondly, for the categorical variable “ISCED”, MICE RF with 10 trees, MICE RF with 100 trees and MICE PMM all performed well. In the aspect of z-score, the MICE RFs (with 10 or 100 trees) had smaller z-scores between 0 and 2 in all 4 ISCED categories. Although the z-scores of MICE PMM in categories ISCED [2] (-3.6714) and ISCED [5] (2.1187) were little large, compared with the results of MICE PMM in continuous variables "age" (9.8557) and "BMI" (9.8597), it can still be regarded as good performance. In terms of CI length and CI coverage, MICE RF with 10 or 100 trees and MICE PMM reached around 92%~95%, and the CI length of MICE PMM was slightly shorter than MICE RFs in all ISCED categories. MICE RF with 100 trees had a little improvement in contrast to 10 trees with smaller z-sore, narrower CI but slightly lower CI coverage. It is also worth noting that the actual CI coverage of "ISCED" of Full data was more anti-conservative than MICE RFs and MICE PMM. However, this does not mean that Full data had poor performance, because it had smaller z-scores between 0 and 2 and shorter CI lengths. Generally speaking, the narrower the confidence interval given 95% nominal confidence, the smaller the result's uncertainty. On the one hand, a narrow confidence interval means that there may be less chance of including the true value in the interval. On the other hand, the small CI coverage using Full data may be due to the uneven distribution of ISCED categories (as shown in Table 2, ISCED [1], [2], and [4] are 1.5%, 7.3%, and 16.2%; ISCED [3], [5] are 34.0% and 40.7%). The result of Full data was based on the random sampled n=2000 Dataset C, and the true values were the estimates based on the complete Dataset B (ISCED [3], [5] may have the main effect on the estimation). Whether MICE PMM or MICE RF, the imputed values of ISCED were more likely to be affected by more observation categories ISCED [3] and ISCED [5], and these categories tended to be the imputed values, which results in that the confidence intervals using MICE PMM and MICE RF may more possibly contain the true value and have higher CI coverage.

Finally, the focus is on the 2 interaction items “age:sex" and "age:bmi" in the analysis model. As mentioned before, because of the poor imputation performance for "BMI" using MICE RFs, the regression performance of "age:bmi" was also poor. Compared with MICE PMM, MICE RF with 10 trees and MICE RF with 100 trees both had larger z -scores (-12.2784 vs. -55.8406, -40.9989) and poor actual CI coverages (91.1% vs. 66.8%, 76.7%), the CI length of MICE PMM was also slightly shorter than that of MICE RFs (0.0122 vs. 0.0146, 0.0140). However, "age:sex" performed well, but the CI coverages were conservative (more than 95%) whether MICE RFs or MICE PMM. Using MICE RF with 100 trees had a smaller z-score (0.6016 vs. -2.9764) and a shorter CI length (0.0080 vs. 0.0082) compared to 10 trees, and although MICE PMM had a slightly larger z-score (2.9360), CI length was shorter (0.0072). Just like the conclusions of continuous variables and categorical variables, adding trees in the random forest could improve the performance of MICE RF.

 
 
 




### Setting 2

The emphasis of Setting 2 is the impact of the sample size (n=200 or 1000) and the proportion of missing (5% or 20%) on the parametric MICE PMM and MICE RF with 10 trees (denoted as MICE RF). The main findings of setting two were that the increase in sample size reduced the CI length with slight loss of CI coverage when using MICE PM and MICE RF, but increased the z-scores. MICE RF performed well on the categorical variable "ISCED", but in comparison, MICE PMM had better performance on all variables overall.

Setting 2 compared the 3 "patterns" (Full data, MICE RF and MICE PMM) described in Section 4.2.2 under 4 combinations of sample sizes (200, 1000) and missing ratios (5%, 20%). The simulation results are shown in Table 15, "n (%)" represents sample size and missing ratio, e.g. "200 (5%)" means the sample size is 200 and the missing ratio is 5%. The utilized analysis model was $\text{log.waist} =  \text{sex + age + bmi + isced} + \text{sex.age + age.bmi}$, an the applied imputation model in MICE PMM and MICE RF was ($\text{sex, age, bmi, isced, log.waist}$), no interactions and nonlinear terms in imputation model were considered when using MICE PMM. The detailed results are as follows.

First of all, the impact of sample size changes on imputation performance is concerned. Whether Full data, MICE PMM or MICE RF, as the sample size increased from 200 to 1000, the average CI length was narrowed under the given 95% confidence level (e.g. "age" MICE RF with 5% missing and n=200 to 1000: 0.0271 vs. 0.0119; with 20% missing: 0.0309 vs. 0.0135). The sample size of this simulation was large enough that the central limit theorem can be called. According to the calculation formula of the confidence interval ${\displaystyle \left({\bar {x}}-1.96{\sigma  \over {\sqrt {n}}},{\bar {x}}+1.96{\sigma  \over {\sqrt {n}}}\right)}$, logically speaking, the larger the sample size, the more accurate the predicted confidence interval. When further comparing with the results in Table 14 (sample size n=2000 and missing ratio 20%), it can be found that the rate of narrowing the confidence interval slowed down as the sample size increased (e.g. for "BMI" using MICE PMM with 20% missing: n=200: 0.2449; n=1000 0.1088; n=2000: 0.0770). Moreover, when the sample size grew, the z-scores of MICE RF and MICE PMM expanded basically. When comparing MICE RF and MICE PMM, the results illustrate that both MICE RF and MICE PMM performed well in the categorical variable "ISCED", MICE RF may be slightly better with the smaller z-score (e.g. ISCED [2] 200 (20%): MICE RF 0.0464 vs. MICE PMM 1.8350), but MICE PMM had a smaller z-score and a narrower CI length in continuous variables and interaction terms. There was basically no difference between MICE PMM and MICE RF in the term of CI coverage, they both reached about 90% or better. However, under a small sample size and a small missing ratio the CI coverages in some cases were conservative.

Secondly, the focus is shifted to the impact of increasing the missing ratio from 5% to 20% on imputation performance. For continuous variables "age", "BMI" and the interaction terms "age:bmi", "age:sex", the improved missing ratio increased the z-score whether using MICE RF or MICE PMM, but MICE PMM had smaller z-scores compared to MICE RF (e.g., "age" n=200: MICE RF with 5% missing 3.4211 vs. with 20% missing: 15.5894; MICE PMM with 5% missing -1.0827 vs. with 20% missing 2.4658). For variable "ISCED", the z-scores of MICE PMM and MICE RF basically were between -1 and 1. The increase in the missing ratio may expand the CI length and increase the CI coverage in all variables, the CI coverage using MICE RF and MICE PMM both can reach around 90%, but MICE PMM was slightly narrower than that of MICE RF (e.g., ISCED [2] n=200 with missing ratio 5%: MICE RF 0.1893 vs. MICE PMM 0.1824).

```{r echo=F,message = FALSE, error = FALSE, warning = FALSE}
load("~/Library/Mobile Documents/com~apple~CloudDocs/05. Masterarbeit/04_Masterarbeit/01_Data/01_linear_regression_V03/results_lm_S2_1.RData")
load("~/Library/Mobile Documents/com~apple~CloudDocs/05. Masterarbeit/04_Masterarbeit/01_Data/01_linear_regression_V03/results_lm_S2_2.RData")
load("~/Library/Mobile Documents/com~apple~CloudDocs/05. Masterarbeit/04_Masterarbeit/01_Data/01_linear_regression_V03/results_lm_S2_3.RData")
load("~/Library/Mobile Documents/com~apple~CloudDocs/05. Masterarbeit/04_Masterarbeit/01_Data/01_linear_regression_V03/results_lm_S2_4.RData")


data_complete$sex <- as.factor(data_complete$sex)
best.fit <- lm(log.waist ~  age + bmi + sex + isced + sex:age + 
                 age:bmi, data = data_complete)
coef <- summary(best.fit)$coefficients[ ,1]

methods <- c('full', 'rf10', 'micepmm')
Model_names <- rep(c("Full data","RF MICE with 10 trees","Parametric MICE PMM"),times=10)

results <- results_lm_S2_1
resultsTable_lm_S2_1 <- Table_lm(results_lm_S2_1,3)

results <- results_lm_S2_2
resultsTable_lm_S2_2 <- Table_lm(results_lm_S2_2,3)

results <- results_lm_S2_3
resultsTable_lm_S2_3 <- Table_lm(results_lm_S2_3,3)

results <- results_lm_S2_4
resultsTable_lm_S2_4 <- Table_lm(results_lm_S2_4,3)


resultsTable_lm_S2_1$Models <- rep(c("Full data","MICE RF","MICE PMM"),10)

S2_1 <- cbind(resultsTable_lm_S2_1[-c(1:3,10:12),],"n (%)"=rep(" 200 ( 5%)",24),  order1=c(1:24),order2=rep(1,24))
S2_2 <- cbind(Variables="",Models="", resultsTable_lm_S2_2[-c(1:3,10:12),-c(1,2)],"n (%)"=rep(" 200 (20%)",24), order1=c(1:24),order2=rep(2,24))
S2_3 <- cbind(Variables="",Models="", resultsTable_lm_S2_3[-c(1:3,10:12),-c(1,2)],"n (%)"=rep("1000 ( 5%)",24),order1=c(1:24),order2=rep(3,24))
S2_4 <- cbind(Variables="",Models="", resultsTable_lm_S2_4[-c(1:3,10:12),-c(1,2)],"n (%)"=rep("1000 (20%)",24),order1=c(1:24),order2=rep(4,24))
S2 <- rbind(S2_1,S2_2,S2_3,S2_4)
S2 <- S2[order(S2$order1,S2$order2),]

S2_Results <- S2[ ,c(1,2,8,3,4,5,6,7)]
rownames(S2_Results) <- NULL

knitr::kable(S2_Results, 
             row.names = NA,
             format  = "pandoc", 
             align = 'c',
             caption = "The effect of sample size and missing ratio using linear regression")
```



### Setting 3

The focus of Setting 3 is to explore the impact of including interaction or nonlinear terms in the imputation model on MICE PMM compared to the non-parametric approach of MICE RF. Considering more interactions and nonlinear relationships in the imputation model can effectively improve the performance of MICE PMM with smaller z-score and increased CI coverage. MICE RF performed well in the categorical variable "ISCED", but in other respects, whether or not interaction and nonlinear relationships were specified in the imputation model, the parametric MICE PMM can lead to more reliable inferences.

In detail, Setting 3 compared 4 "patterns" described in Section 4.2.3: Full data (complete Dataset C with n=2000), MICE RF with 10 trees (MICE RF), MICE PMM 1 (including interaction and nonlinear terms in the imputation model), MICE PMM 2 (not including interaction or nonlinear terms in the imputation model same as Setting 1), Table 16 displays the simulation results. MICE PMM 1 considers all two-way interaction terms among 5 main variables, and 3 quadratic terms of continuous variables, the applied imputation model of MICE PMM 1 was ($\text{sex, age, bmi, isced, log.waist}$, $\text{age:sex}$, $\text{age:bmi}$, $\text{age:isced}$, $\text{age:log.waist}$, $\text{sex:bmi}$, $\text{sex:isced}$, $\text{sex:log.waist}$, $\text{bmi:isced}$, $\text{bmi:log.waist}$, $\text{isced:log.waist}$, $\text{age}^2$, $\text{bmi}^2$, $\text{log.waist}^2$). The imputation model  ($\text{sex, age, bmi, isced, log.waist}$) was utilized for MICE PMM 2. MICE RF did not need to specify interaction and nonlinear relationships in the imputation model, only ($\text{sex, age, bmi, isced, log.waist}$) were considered in the imputation model. Futhermore, the analysis model of Setting 3 was $\text{log.waist} =  \text{sex + age + bmi + isced} + \text{sex.age + age.bmi}$.

As seen from Table 16, MICE PMM 1 had a smaller z-score and higher CI coverage than MICE PMM 2, and the CI length of MICE PMM 1 was close to MICE PMM 2 (e.g. for "age" using MICE PMM 1 with 5.3981 z-score and 97.3% CI coverage, using MICE PMM 2 was 9.8557 and 96.2%). However, MICE PMM 2 may result in slightly larger confidence intervals for interaction terms and continuous variables. For categorical variable "ISCED", MICE RF had the smallest z-score, and the CI coverage for all categories reached around 94%. For other variables "age" and "BMI", and interaction terms "age:bmi" and "age:sex" in the analysis model, regardless of whether interaction and quadratic terms were included in the MICE PMM imputation model, MICE RF did not perform as well as MICE PMM 1 and MICE PMM 2 except for "age:sex", which had a smaller z-score -2.0415 and 98.0% CI coverage, other z-scores were very large ("age": 46.0198, "BMI": 49.5299), CI lengths were longer, and CI coverages were less than 90%. It could be considered that MICE RF may have advantages in categorical variables, but MICE PMM had wider applicability and can perform better in any variable type, and adding interaction and nonlinear relationships to the imputation model can improve the performance using MICE PMM. There may be two reasons for the poor imputation performance of continuous variables and interaction term "age:bmi" using MICE RF. One is that the MICE RF algorithm used in this thesis (Algorithm 6 in Section 3.7) may be more suitable for variables with normal distribution, because the imputed values were randomly drawn from a normal distribution given the conditional mean defined using random forest; the other may be that the derived variable "BMI" was directly imputed instead of its component variables, which may lead to unreasonable imputed values. The imputation method for interactions using parametric MICE PMM was passive imputation, so when the continuous variable imputation performance was poor, the imputation performance of the imputation terms may also be worse. Finally, it should be pointed out that the CI of "age" (using Full data and MICE PMMs) and the interaction term "age:sex" (all 4 patterns) may not be conservative, the CI coverages were obviously greater than 95%.



```{r echo=F,message = FALSE, error = FALSE, warning = FALSE}
load("~/Library/Mobile Documents/com~apple~CloudDocs/05. Masterarbeit/04_Masterarbeit/01_Data/01_linear_regression_V03/results_lm_S3.RData")

best.fit <- lm(log.waist ~  age + bmi + sex + isced + sex:age + 
                 age:bmi, data = data_complete)
coef <- summary(best.fit)$coefficients[ ,1]

methods <- c('full', 'rf10', 'micepmm')
Model_names <- rep(c("Full data","MICE RF","MICE PMM 1"),times=10)
results <- results_lm_S3
resultsTable_lm_S3 <- Table_lm(results_lm_S3,3)



methods <- c('full', 'rf10', 'rf100', 'micepmm')
Model_names <- rep(c("Full data","RF MICE with 10 trees",
                     "RF MICE with 100 trees","MICE PMM 2"),
                   times=10)
results <- results_lm_S1
resultsTable_lm_S3_2 <- Table_lm(results_lm_S1,4)

S3_Results <- rbind(resultsTable_lm_S3[c(4:6),],
                    resultsTable_lm_S3_2[8,],
                    resultsTable_lm_S3[c(7:9),],
                    resultsTable_lm_S3_2[12,],
                    resultsTable_lm_S3[c(13:15),],
                    resultsTable_lm_S3_2[20,],
                    resultsTable_lm_S3[c(16:18),],
                    resultsTable_lm_S3_2[24,],
                    resultsTable_lm_S3[c(19:21),],
                    resultsTable_lm_S3_2[28,],
                    resultsTable_lm_S3[c(22:24),],
                    resultsTable_lm_S3_2[32,],
                    resultsTable_lm_S3[c(25:27),],
                    resultsTable_lm_S3_2[36,],
                    resultsTable_lm_S3[c(28:30),],
                    resultsTable_lm_S3_2[40,])

rownames(S3_Results) <- NULL
knitr::kable(S3_Results,
             format  = "pandoc", 
             row.names = NA,
             caption = "The interactions and nonlinear terms in the imputation model using linear regression")
```





## Results using conditional independence test

When evaluating performance using MICE PMM and MICE RF, not only linear regression was considered, but also conditional independence test (focusing on Fisher's z-test) was part of the evaluation approach. Tables 17-19 show the results of Setting 1-3 using Fisher's z-test between "log.waist" and "BMI" given "age". However, even if the sample size was 200 and the missing ratio was 20%, the power of conditional independence test using MICE PMM and MICE RF reached 100% in all Settings. Because the actual true value under $H_1$ was very far from zero, the observed partial correlation between "log.waist" and "BMI" given "Age" was around 0.72; therefore, no null hypothesis was easily rejected.

Section 5.2.1 discusses the actual type 1 error of the 3 Settings described in Section 4.2 given nominal $\alpha=0.05$. The studies found that the actual type 1 errors using MICE RF and MICE PMM can achieve near 4%~7%, and MICE RF had smaller results. However, in some cases, Fisher’s z-test was not conservative. And considering the interaction and nonlinear relationships in the imputation model can improve the performance of the test. In section 5.2.2, the small simulation studies were supplemented to explore the power of MICE RF and MICE PMM under the smaller sample size and the larger missing ratio. The power of Fisher's z-test using MICE PMM was greater than MICE RF, but as the sample size increased and the missing ratio decreased, the power of both reached 100%.




### Type 1 error

Setting 1 compared the actual type 1 errors under 4 "patterns" (described in Section 4.2.1): Full data (based on n=2000 dataset without missing), MICE RF with 10 trees, MICE RF with 100 trees and parametric MICE PMM, when the sample size was 2000 and the missing rate was 20%. The imputation models for MICE PMM and two MICE RFs were the same, only 5 main variables ($\text{sex, age, bmi, isced, log.waist}$) were considered. The powers of the Fisher's z-tests under 4 patterns described in Section 4.2.1 were 100%, the observed partial correlation between "log.waist" and "BMI" given "age" was 0.7216 (SD: 0.0104) in 1000 simulations.

Table 17 illustrates intuitively that the actual type 1 errors of the three MICEs were less than 5% and were close to Full data (4.5%). Compared to the parametric MICE PMM (4.4%), the type 1 errors of MICE RFs were smaller, and the performance of MICE RF with 100 trees was slightly better than 10 trees (4.1% vs. 3.9%), the increase of trees in the random forest did not greatly improve the performance of the Fisher's z-test. However, when discussing a test, it is necessary to consider its conservative. Given the nominal significance level of $\alpha = 0.05$, in Table 17, the actual type 1 error of 4 "patterns" was lower than the nominal type 1 error. Therefore, Fisher's z-test in Setting 1 was conservative.



```{r echo=F,message = FALSE, error = FALSE, warning = FALSE}
## Load data
load("~/Library/Mobile Documents/com~apple~CloudDocs/05. Masterarbeit/04_Masterarbeit/01_Data/02_lndependence_Test_V03/results_CIT_S1.RData")
load("~/Library/Mobile Documents/com~apple~CloudDocs/05. Masterarbeit/04_Masterarbeit/01_Data/02_lndependence_Test_V03/results_CIT_S2_1.RData")
load("~/Library/Mobile Documents/com~apple~CloudDocs/05. Masterarbeit/04_Masterarbeit/01_Data/02_lndependence_Test_V03/results_CIT_S2_2.RData")
load("~/Library/Mobile Documents/com~apple~CloudDocs/05. Masterarbeit/04_Masterarbeit/01_Data/02_lndependence_Test_V03/results_CIT_S2_3.RData")
load("~/Library/Mobile Documents/com~apple~CloudDocs/05. Masterarbeit/04_Masterarbeit/01_Data/02_lndependence_Test_V03/results_CIT_S2_4.RData")
load("~/Library/Mobile Documents/com~apple~CloudDocs/05. Masterarbeit/04_Masterarbeit/01_Data/02_lndependence_Test_V03/results_CIT_S3_2.RData")




methods <- c('rf10', 'rf100', 'micepmm')
Model_names <- c("RF MICE with 10 trees",
                 "RF MICE with 100 trees",
                 "Parametric MICE PMM")
results <- results_lm_S1
lm <- Table_CIT(results_lm_S1)
results <- results_CIT_S1
CIT <- Table_CIT(results_CIT_S1)
## CIT$Ratio <- 1-CIT$Ratio
resultsTable_CIT_S1 <- cbind(lm,CIT)[,-3]
colnames(resultsTable_CIT_S1) <- c('Models','Power','Type 1 error')
```

-----------------------------------------------
         Models           Power   Type 1 error 
------------------------ ------- --------------
       Full Data           100%        4.5%     

 MICE RF with 10 trees     100%        4.1%     

 MICE RF with 100 trees    100%        3.9%     

  Parametric MICE PMM      100%        4.4%     
-----------------------------------------------
Table:\centering The impact of tree number using conditional independence test



Setting 2 focus on the impact of changes in sample size (n=200, 1000) and missing ratio (5%, 20%) under 3 "patterns" described in Section 4.2.2: Full data, MICE PMM and MICE RF  (with 10 trees) were compared under 4 combinations of sample size and missing ratio in Table 18, "n (%)" represents the sample size and missing ratio. The powers of the Fisher's z-tests under 3 patterns were 100%, and the observed partial correlation between "log.waist" and "BMI" given "age" was 0.7210 (SD: 0.0289) when n=200, 0.7192 (SD: 0.0151) when n=1000. The imputation model was the same as Setting 1, which was ($\text{sex, age, bmi, isced, log.waist}$) for MICE RF and MICE PMM.

As demonstrated in Table 18, when the sample size developed and the missing ratio increased, the actual type 1 error tended to increase in 3 patterns (e.g., MICE PMM n=200 with 5% to 20% missing: 4.1% to 5.7%; n=1000: 6.6% to 6.9%). However, one exception occurred when the sample size was 1000 and the missing ratio changed from 5% to 20%, the actual type 1 error of MICE RF reduced from 6.0% to 5.5% by 0.5%. On the one hand, this reduction may be accidental due to random errors. On the other hand, the actual type 1 error only increased by 0.3% for MICE PMM with sample size of n=1000 and the missing ratio from 5% to 20%. Therefore, another possible explanation is that when the sample size was small, both MICE PMM and MICE RF were more sensitive to the missing ratio, but as the sample size increased, MICE PMM was more robust. When comparing MICE PMM and MICE RF, the actual type 1 errors using MICE RF and MICE PMM were equivalent under sample size n=200 and missing ratio 5% (4.2% vs. 4.1%); but under other sample sizes and missing ratio, the performance using MICE RF was slightly better than MICE PMM (n=200 with 20% missing: 5.4% vs. 5.7%; n=1000 with 5% missing: 6.0% vs. 6.6%; n=1000 with 20% missing: 5.5% vs. 6.9%). It should also be noted that Fisher’s z-test was conservative in the case of a small sample and small missing ratio, and the actual type 1 error was less than 5%.


```{r echo=F,message = FALSE, error = FALSE, warning = FALSE}
## results_lm_S2_200_5      0.7210 (0.0289)
## results_lm_S2_200_20     0.7189 (0.0324)
## results_lm_S2_1000_5     0.7192 (0.0151)
## results_lm_S2_1000_20    0.7218 (0.0145)
```


----------------------------------------------------------------------
          Models                n (%)            Power   Type 1 error 
----------------------- ----------------------- ------- --------------
      Full Data              200 ( 5%)           100%        4.8%     

                             200 (20%)           100%        5.1%     

                            1000 ( 5%)           100%        5.5%     

                            1000 (20%)           100%        6.0%     
                            
       MICE RF               200 ( 5%)           100%        4.2%     
 
                             200 (20%)           100%        5.4%     

                            1000 ( 5%)           100%        6.0%     

                            1000 (20%)           100%        5.5%     

       MICE PMM              200 ( 5%)           100%        4.1%    
  
                             200 (20%)           100%        5.7%     

                            1000 ( 5%)           100%        6.6%     

                            1000 (20%)           100%        6.9%   
----------------------------------------------------------------------
Table: \centering The effect of sample size and missing ratio using conditional independence test



 

 



```{r echo=F,message = FALSE, error = FALSE, warning = FALSE}
methods <- c('full','rf10', 'micepmm')
Model_names <- c("Full Data","RF MICE with 10 trees",
                 "Parametric MICE PMM")

results <- results_lm_S3
lm <- Table_CIT(results_lm_S3)

results <- results_CIT_S3
CIT <- Table_CIT(results_CIT_S3)

resultsTable_CIT_S3 <- cbind(lm,CIT)[,-3]
colnames(resultsTable_CIT_S3) <- c('Models','Power','Type 1 error')


### Calculate partucal correlation
method <- c('full')
results <- results_lm_S3
Correlation <- sapply(results, function(x){
  as.numeric(x[[method]][ , 'pcor'])
})
Correlation <- Correlation[1,]
pcor <- summary(Correlation)
## sd(Correlation)
## 0.7216 (0.01038)
```

Setting 3 aims to compare the impact of including the interactions and nonlinear terms in the imputation model on the conditional independence test. The 4 "patterns" described in Section 4.2.3 were compared, and the results were shown in Table 19: Full data (Complete Dataset C with n=2000), MICE RF (with 10 trees), MICE PMM 1 (all two-way interactions and 3 quadratic terms for continuous variables were included in the imputation model ) and MICE PMM 2 (without considering interaction and nonlinear terms in the imputation model). As indicated in Table 19, MICE RF had the smaller actual type 1 error (4.1%), and the inclusion of interaction and nonlinear effects in the imputation model for MICE PMM may increase the actual type 1 error (MICE PMM 1: 5.1% vs. MICE PMM 2: 4.4%). However, when using MICE RF and MICE PMM 2 (same as Setting1), Fisher's z-test did not achieve good performance because the test was conservative (the actual type 1 error was smaller than the nominal lever 5%). In contrast, the performance of MICE PMM 1 should be considered good because it had slightly exceeded the nominal level of 5%.

----------------------------------------------
        Models           Power   Type 1 error 
----------------------- ------- --------------
       Full Data          100%        4.5%     

        MICE RF           100%        4.1%     

      MICE PMM 1          100%        5.1%     
      
      MICE PMM 2          100%        4.4%    
----------------------------------------------
Table:\centering The interactions and nonlinear terms in the imputation model using conditional independence test



### Power

This section compares the power of the conditional independence test using MICE RF (with 10 trees) and MICE PMM in the case of the smaller sample size (less than 100) and the larger missing ratio (greater than 50%) in 100 simulations. Table 20 illustrates the power of the conditional independence test when the missing ratio increased under a fixed sample size of 30, 50, and 70, and "n (%)" denotes the sample size and missing ratio, "Correlation" represents the observed partial correlation between "log.waist" and "BMI" given "age", "MICE RF" and "MICE PMM" are the power of Fisher's z-test between "log.waist" and "BMI" given "age" using MICE RF with 10 trees and MICE PMM under given sample size and missing ratio.

In the case of a small sample size (n=30), the power was very sensitive to the missing ratio. As the missing ratio grew from 50% to 80%, the power fast decreased. However, the power using MICE PMM was larger than the MICE RF all the time, and MICE PMM was more robust with a slower decline rate (MICE RF: 87%-53%; MICE PMM: 95%-73%).

Under a larger sample size (n=50, 70), when the missing ratio increased, although the powers using MICE RF and MICE PMM decreased slightly, it was no longer sensitive to the missing ratio, because the powers did not shrink rapidly with the increase in the missing ratio (e.g. n=50, MICE RF with 50% missing: 95%; with 80% missing: 92%). Comparing with MICE RF, MICE PMM had a slight advantage with smaller power, but when the sample size gradually expanded and the missing proportion decreased, the power of both MICE PMM and MICE RF reached 100%.


|   n (%)   | Correlation | MICE RF | MICE PMM |
|:---------:|:-----------:|:-------:|:--------:|
| 30 (50 %) |    0.7334   |   87 %  |   95 %   |
| 30 (60 %) |    0.7384   |   75 %  |   91 %   |
| 30 (70 %) |    0.7308   |   54 %  |   83 %   |
| 30 (80 %) |    0.7408   |   53 %  |   73 %   |
|           |             |         |          |
| 50 (50 %) |    0.7254   |   95 %  |   99 %   |
| 50 (60 %) |    0.7307   |   92 %  |   98 %   |
| 50 (70 %) |    0.7310   |   92 %  |   96 %   |
| 50 (80 %) |    0.7313   |   92 %  |   97 %   |
|           |             |         |          |
| 70 (50 %) |    0.7247   |  100 %  |   100 %  |
| 70 (70 %) |    0.7261   |   99 %  |   99 %   |
| 70 (80 %) |    0.7231   |   99 %  |   100 %  |
| 70 (90 %) |    0.7256   |   95 %  |   98 %   |
Table: Power comparisons under sample size 30, 50 and 70


 
 




# Discussion

Chapter 6 is a discussion of the results at the end of this thesis. First, it summarizes the main findings of this thesis, and then compares the advantages and disadvantages of the two methods MICE PMM and MICE RF based on the results. The last part of this chapter states the weaknesses of this thesis.

**Summary of Results**

In this thesis, the linear regression and conditional independence test (focusing on Fisher's z-test) in 3 settings were applied as evaluation approaches to compare the performance of MICE RF and MICE PMM based on the IDEFICS data. 

When using linear regression as the analysis method, MICE RF had advantages in the categorical variable "ISCED", which can provide a smaller z-score. However, in terms of the CI length and CI coverage, the performance using MICE PMM was slightly better with higher CI coverage and shorter CI length for the categorical variable. Moreover, MICE PMM performed better than MICE RF in all 3 Settings for other variables with smaller z-scores, shorter CI and higher coverage. 

* When focusing on the impact of trees in the random forest on MICE RF (Setting 1), the increased trees had an improvement on performance using MICE RF; 
* When examining the impact of sample size and missing ratio on MICE PMM and MICE RF (Setting 2), the increase of sample size shortened the average CI length, and the grown sample size and missing ratio expanded the z-score;
* When the interactions and quadratic terms were considered in the imputation model of MICE PMM (Setting 3), the performance of MICE PMM was improved.

When using the conditional independence test (Fisher's z-test) to compare MICE PMM and MICE RF performance under 3 settings, actual type 1 errors using MICE RF and MICE PMM reached 4%~7%, and MICE RF was slightly smaller than MICE PMM. However, the actual type 1 error was less than the nominal level 0.05 in some cases, the test was conservative. In addition, 

* MICE RF with 100 trees had a smaller actual type 1 error than with 10 trees (Setting 1); 
* the increase of sample size and the missing ratio might enlarged the type 1 error (Setting 2); 
* the actual type 1 error reached the nominal level when interactions and nonlinear terms were included in the imputation model of MICE PMM (Setting 3). 

Because the observed partial correlation between "log.waist" and "BMI" given "age" was around 0.72, which was very far from zero under $H_1$. The power of Fisher's z-test for both MICE PMM and MICE RF has reached 100% under 3 settings. So that a supplementary study was conducted to explore the great missing ratio (>50%) and the small sample size (<100) on the power of the conditional independence test. The results indicated that the increase in sample size and the decrease in the missing ratio promoted the increase of power for MICE PMM and MICE RF, and the performance of MICE PMM was superior to that of MICE RF. However, this advantage was offset by the increase in sample size and the decrease in the missing ratio. Under the large sample size (greater than 100) and the relatively small missing ratio (less than 50%), the power of Fisher z-test using MICE PMM and MICE RF can provide good performance.


 
 

**MICE PMM versus MICE RF**

The merits and demerits of MICE PMM and MICE RF are further discussed based on the results. First of all, MICE PMM does not need to specify imputation models for continuous variables and categorical variables separately, the imputation models for all variable types are "pmm". But MICE RF must specify "rfcont10" or "rfcont100" for continuous variables, "rfcat" for the categorical variable (See Appendix code). In addition, in terms of program running time, MICE PMM required the shortest time. The time consumption of MICE RF with 10 trees was close to that of MICE PMM, but the time cost of MICE RF with 100 trees was about 10 times that with 10 trees. Compared with MICE PMM, the great advantage of MICE RF is that it can automatically adapt to nonlinearities and interactions between variables without parametric assumptions, interactions and nonlinear terms do not need to be specified in the imputation model. In Setting 3 of this thesis, MICE PMM must specify imputation models for all two-way interactions and quadratic terms, which was quite tedious. If the interest was mainly focused on estimating the interaction effect, MICE PMM with correctly specified parametric imputation model and tree-based MICE may perform similarly, and the CI coverage using MICE PMM may be better (Slade et al., 2020). However, there are often hundreds of variables in complex research. Correctly identifying the associations between these variables and specifying them in the imputation model will be a laborious task for MICE PMM (Burgette et al., 2010). Therefore, the choice of MICE PMM or MICE RF also needs to be considered based on specific research.

Secondly, MICE PMM adapts to almost all variable types. And MICE PMM is less susceptible to model misspecification, which is robust compared with other models, this method can also be used to deal with skewed continuous variables (White et al., 2009). As stripplots for variables "age" and "BMI" shown in Figure 9, PMM drew the imputed values from the real observed values for each variable, the imputation using MICE PMM was always conducted within the range of observed data, meaningless imputations can be avoided and may reduce the bias. But for "BMI", the imputed value obtained by using MICE RF may be greater than 1, while "BMI" was the converted percent variable between 0 and 1. 

Finally, the distribution of the imputed values using MICE PMM matched the distribution before imputation (Figure 10). Figure 10 shows the density plots of "age" and "BMI" using Full data (n=2000 without missing), MICE RF with 10 trees, MICE RF with 100 trees and MICE PMM, which compares the distribution of the observed data (the blue line means the distribution of the observed data) and the imputed data (the red lines refer to the 10 imputed datasets). It is also found that the imputed data using MICE RFs was normally distributed. Because the applied MICE RF Algorithm in this thesis (Section 3.7 Algorithm 6) assumed conditional normality and constant variance from the random forest regression (Bartlett et al., 2014). The imputed values were randomly drawn from the independent normal distributions based on conditional mean, which were predicted using random forest (Shah et al., 2014). In Shah's simulation research (2014), the observed continuous variables were approximately normal distributions, MICE PMM and MICE RF have achieved close results. The CI length generated by MICE RF was smaller than the width of MICE PMM, and with equal or greater CI coverage. However, in this thesis, continuous variables were not normally distributed. MICE RF had larger z-scores, wider CI lengths and insufficient CI coverages. When the continuous variable was not a normal or approximate normal distribution, the distribution of the imputed value and the observed value was inconsistent, which may cause bias (Shah et al., 2013).


\begin{center}
\includegraphics[width=6.5in]{Fotos/Density_Full.jpg}
\begin{figure}[!h]
\caption{Density plots for variables "age" and "BMI"}
\end{figure}
\end{center}

Nevertheless, it is undeniable that the predicted mean matching still has some pitfalls. The most obvious is that when the sample is small or the proportion of missing is too high, multiple repeated donor values will appear in the imputed datasets. In extreme cases, if there are only a few predictors in the sample, PMM cannot be used. However, this study had sufficient donors in the categorical variable "ISCED" and continuous variables, and the sample size was large. Futhermore, Van Buuren (2012) indicated that correctly specifying the imputation model was more important, when the imputation model was misspecified, performance using MICE PMM may deteriorate if there were strong nonlinear relations or interactions in the model. In this thesis, including all two-way interactions and 3 quadratic terms for continuous variables in the imputation model improved the performance of MICE PMM slightly, the performance using MICE PMM without including interactions and nonlinear terms reached a good level.



Regardless of MICE PMM or MICE RF, the imputation models were not compital or congenial with the analysis models. The congeniality and compatibility between the imputation and analysis model may be crucial to procure valid estimates (Burgess et al., 2013), MICE is an iterative Markov Chain Monte Carlo algorithm, only under compatibility may the convergence of MICE be guaranteed (Van Buuren et al., 2006). When checking the convergence of the MICE algorithms for variables "age", "BMI" and "ISCED" in Figures 11-13, the different colored curves in the subplots represent trace lines for 10 imputed datasets. As figures showed, these streams are mixed, and there is no trend in later iterations, which means that whether MICE PMM or MICE RFs the algorithm converged well. Van Buuren et al. (2006) demonstrated that the impact of compatibility on the statistical inference was still unclear, and accurate compatibility was easily destroyed in actual data analysis (simple rounding errors). Even under incompatibility MICE may also provide the basic unbiased estimation. For this reason, incompatibility may not be the key influencing factor using MICE PMM and MICE RF. Under compatibility and congeniality, MICE possibly produce better performance, it can be explored in future research.

\begin{center}
\includegraphics[width=6in]{Fotos/convergence_pmm.png}
\begin{figure}[!h]
\caption{Convergence checking using parametric PMM}
\end{figure}
\end{center}

\begin{center}
\includegraphics[width=6in]{Fotos/convergence_rf10.png}
\begin{figure}[!h]
\caption{Convergence checking using MICE RF with 10 trees}
\end{figure}
\end{center}

\begin{center}
\includegraphics[width=6in]{Fotos/convergence_rf100.png}
\begin{figure}[!h]
\caption{Convergence checking using MICE RF with 100 trees}
\end{figure}
\end{center}









**Weaknesses and Prospects**

All in all, this thesis discovered the application potential of MICE RF in the independence test focusing on Fisher's z-test, which was not covered in previous studies. In addition, when using linear regression as the analysis method, MICE RF was suitable for imputing categorical variables, and when continuous variables are approximately normal distribution, MICE RF may achieve better performance. 

However, this is indeed a complex study. The design of the simulation study took a lot of time in the simulation process. For example, how to better organize simulation studies using two analysis methods under three settings, how to choose the analysis model and the imputation model correctly. Besides, the writing and running of the simulation code also spent a lot of time. Under three settings, linear regression and conditional independence test (actual type 1 error) cannot use the same imputed datasets. Theoretically, at least 6000 simulations must be performed, and actually more. When using 100 trees of MICE RF, each simulation needed about 6 minutes. In other cases, each simulation took about 70 seconds. In a limited work time, this thesis still has the following shortcomings.

First is the variable selection. There are hundreds of variables in IDEFICS data. The original intention in variable selection is to choose the variable with the lowest percentage of missing. The variable "BMI" was 100% observed without any missing. However, "BMI" was a transformed variable, after calculating using ${\displaystyle \mathrm {BMI} ={\frac {{\text{mass}}_{\text{kg}}}{{{\text{height}}_{\text{m}}}^{2}}}}$, the "BMI" was standardized as percent in the interval [0,1] calculated according to Cole & Lobstein (2012). According to Van Buuren's guidance in “Flexible Imputation of Missing Data” (2012), it is not wise to directly impute in the derived variables, which may lead to unreasonable imputed values and cause bias. In this study, the imputed "BMI" values were not expected to be greater than 1 or less than 0. However, as shown in Figure 9, using MICE RFs caused abnormal imputed values. Therefore, the component variables of the transformed variables should be imputed (e.g. variables "weight" and "height"), and then the transformed variable "BMI" can be generated after imputation. Besides, for the power of Fisher’s z-test, the actual true value under $H_1$ was very far from zero, the observed partial correlation between "log.waist" and "BMI" given "Age" was 0.72, which results that no null hypothesis was easily rejected. If the partial correlation between the selected continuous variables is close to zero, the power of the conditional independence test using MICE PMM and MICE RF may be better compared.

Secondly, other auxiliary variables were not included in this study. Regardless of whether the predictor variables had missing values, all variables in the analysis model should be contained in the imputation model (Schafer, 1997). In this way, the MAR assumption can be more plausible to reduce the bias, and the standard error of the estimates in the analysis model can be decreased (White et al., 2009). Including appropriate auxiliary variables in the imputation model has been proven to be beneficial (Hardt et al., 2012). When the auxiliary variables were highly correlated with the predictor variables or responses variable, involving those variables in the imputation model could profit the more reasonable MAR assumption and reduce the bias, especially when the missing ratio was large (Breiman, 2001), it can also maintain the true association between variables. And even though the imputation model was very complicated, it didn't affect the choice of the analysis model. 

As a nonparametric method, MICE RF does not depend on the distribution assumptions of variables, and the process of tree construction in random forests implies the interaction and high correlation between features (Ziegler et al, 2014). However, those merits were not prominent in this thesis. One possible reason is that there were too few variables when constructing random forests. During the model building, random forest randomly chose input features and randomly sampled features during each split. but because of the few total input variables (only 5 variables), the poor performance of the final model may be a foreseeable cost. Therefore, considering more auxiliary variables in the imputation model maybe a perspective for future research, especially MICE RF may produce better estimation using linear regression. However, it cannot be ignored that excessive auxiliary variables in the imputation model may increase the bias and reduce precision using linear regression, as well as computationally expensive (Hardt et al., 2012).

Thirdly, this thesis only considered passive imputation for interaction and nonlinear relationships in the imputation model for Setting 3 when using PMM. However, passive imputation may cause bias for interaction and nonlinear terms (Seaman et al., 2012; Tilling et al., 2016). For example, when the interaction "age:sex" was imputed, the variable "age" was imputed in the conditional model without "age:sex", this model was not compatible with the interaction "age:sex". Bartlett et al. (2015) indicated that using passive imputation the imputation model was misspecified and may result in bias in estimation. Therefore, the conclusion drawn in Setting 3 of this thesis may not be very reliable. In order to achieve a more comprehensive comparison, other imputation methods for interaction and nonlinear terms could also be considered in subsequent research, such as JAV (the interaction or nonlinear terms are regarded as just another variable) (Seaman et al., 2012), the rejection sampling method (the congeniality between the imputation model and the substantive model was satisfied) (Bartlett et al., 2015).


Finally, the distribution of the imputed values of the continuous variable (normal distribution) was not similar to the distribution of the observed values (not normal distribution)) when using MICE RF (Figure 10). Because the imputed values by the MICE RF used in this thesis were randomly derived from the independent normal distribution, where the conditional mean was predicted using random forest (Shah et al., 2014). The assumption of the normal distribution with constant variance using random forest regression is also a limitation of the MICE RF Algorithm used in the thesis. Therefore, when the continuous variables were (approximately) normally distributed, MICE RF may obtain better performance (Shah et al., 2014). For non-normally-distributed variables, MICE PMM may be a better choice (Marshall et al., 2010). This can also be taken into account in future research. Besides, the different MICE RF methods could be used based on IDEFICS data as more comprehensive comparisons, so that the performance of MICE RF can be better evaluated. E.g., missForest (Stekhoven et al.) used an iterative imputation scheme to implement random forest in MICE; based on missForest, the mForest method speeds up the calculation (Tang et al., 2017). Moreover, the Random Forest MICE (Section 3.7 Algorithm 5) proposed by Doove et al. (2014), should be more considered. Because for categorical variables MICE RF used the same algorithm as the Random Forest MICE, and this thesis has proved the potential of MICE RF in categorical variables through simulation studies. Random Forest MICE has no assumptions about normality and constant variance, for continuous and categorical variables, the imputed values are randomly selected from the predictions using random forest. And the bias using Random Forest MICE was smaller than MICE PMM (Doove et al., 2014). Therefore, Random Forest MICE may have better performance in IDEFICS data, which deserves study in the future.





# Appendix Code

```R
#-------------------------------------------------------------------------#
#                        Functions: Data generating                       #
#-------------------------------------------------------------------------#
## sample n=2000 from complete datasets 
## for linear regression
datasample <- function(x,n){
  x <- data_complete[sample(1:nrow(data_complete), 
                            n, replace=TRUE), ]
  return(x)
}

## sample n=2000 from complete datasets 
## for type 1 error of conditional independent tests
dataCITerror <- function(x,n){
  x <- data_complete[sample(1:nrow(data_complete), 
                            n, replace=TRUE), ]
  Model <- lm(bmi ~  age, data=x)
  ## delete all observations in variabe Y='bmi'
  x_miss <- x[,-3]
  ## extract coeficients
  coef <- coef(Model) 
  ## generate new bmi
  x_miss$bmi <- coef[1]+coef[2]*x_miss$age 
  + rnorm(n, mean=0, sd=summary(Model)$sigma)
  x_miss <- x_miss[,c(1,2,5,3,4)]
  return(x_miss)
}

## generate missing data under MAR
## using ampute from "mice" package
makeMarlm <- function(data, missratio, missdata){
  ## convert to numeric datatype
  ## the calculation of weights requires numeric data 
  data$sex <- as.numeric(data$sex)
  data$isced <- as.numeric(data$isced)
  ampute_result1 <- ampute(data, prop = missratio, 
                           mech = "MAR")
  mypatterns <- ampute_result1$patterns
  ## make sure "waist" and 'sex' no missing
  mypatterns <- mypatterns[c(-2,-5),]
  mypatterns <- rbind(mypatterns,c(0,1,0,1,1),
                      c(0,1,1,0,1),c(1,1,0,0,1),c(0,1,0,0,1))
  ## using new predict matrix
  ampute_result2 <- ampute(data, prop = missratio, 
                           mech = "MAR", patterns = mypatterns)
  missdata <- data.frame(ampute_result2$amp)
  ## convert to factor
  missdata$sex <- as.factor(missdata$sex)
  missdata$isced <- as.factor(missdata$isced)
  ## check the missing pattern
  ## dev.off()
  ## md.pattern(missdata)
  return(missdata)
}
```

```R
#-------------------------------------------------------------------------#
#                        Functions: Perform MICE                          #
#-------------------------------------------------------------------------#
## impute data using MICE 
domice <- function(missdata, functions, reps = 10){
  ## conduct mice with specified function: parametric MICE using pmm
  ## random forest MICE using rfcont10 or rfcont100 for continous variables 
  ## using rfcat for catagorical variable
  mids <- mice(missdata, defaultMethod = functions,
               m = reps, visitSequence = 'monotone',
               printFlag = FALSE, maxit = 10)
  return(mids)
}

## RF MICE for continous variables
## n trees = 10
mice.impute.rfcont10 <- function(y, ry, x, ...){
  mice.impute.rfcont(y = y, ry = ry, x = x, ntree_cont = 10)
}
## n trees = 100
mice.impute.rfcont100 <- function(y, ry, x, ...){
  mice.impute.rfcont(y = y, ry = ry, x = x, ntree_cont = 100)
}
```

```R
#-------------------------------------------------------------------------#
#          Functions: Perform anslysis using linear Regression            #
#-------------------------------------------------------------------------#
## Full data analysis for simulation study
lmfull <- function(data){
  ## fit models
  fit <- summary(lm(formular, data = data))
  coefs <- fit$coefficients[ , 1]  
  se <- fit$coefficients[ , 2]
  ## return a vector of coefficients (est)
  ## upper and lower 95% limits 
  confint <- cbind(coefs - qnorm(0.975) * se,
                   coefs + qnorm(0.975) * se) 
  ## calculate coverage
  cover <- ifelse(consist_coef >= confint[,1] & 
                    consist_coef <= confint[,2],1,0)
  p.value <- fit$coefficients[,4]
  out <- cbind(coefs, confint, cover, p.value)
  ## rename
  colnames(out) <- c('est', 'lo 95', 'hi 95', 'cover', 'p value')
  rownames(out) <- c('(Intercept)', 'age', 'bmi', 'sex', 
                     'isced[2]','isced[3]','isced[4]','isced[5]',
                     'age:sex','age:bmi')
  out
}

## Analyses a list of imputed data sets
lmimpute <- function(imputed_datasets){
  ## The as.mira() function takes the results of 
  ## repeated complete-data analysis stored as a list,
  ## Turns it into a mira object that can be pooled.
  dolmmodel <- function(data){
    lm(formular, data=data)
  }
  reps=10
  list_fit <- lapply(1:reps, function(x) 
    complete(imputed_datasets, x))
  mirafits <- as.mira(lapply(list_fit, dolmmodel))
  ## Linear performance
  out <- summary(pool(mirafits))
  ## draw estimators and std.error for CI and cover calculation 
  coefs <- out$estimate
  se <- out$std.error
  ## return a vector of coefficients (est)
  ## and upper and lower 95% limits 
  confint <- cbind(coefs - qnorm(0.975) * se,
                   coefs + qnorm(0.975) * se)    
  p.value <- out$p.value
  out <- cbind(coefs, confint, 
               consist_coef >= confint[,1] & 
                 consist_coef <= confint[,2], p.value)
  ## rename
  colnames(out) <- c('est', 'lo 95', 'hi 95', 'cover', 'p value')
  rownames(out) <- c('(Intercept)', 'age', 'bmi', 'sex', 
                     'isced[2]','isced[3]','isced[4]','isced[5]',
                     'age:sex','age:bmi')
  out
}
```


```R
#-------------------------------------------------------------------------#
#                            Analysis Setting 1                           #
#-------------------------------------------------------------------------#
## linear regression: methods comparation using list
## Calculate Fisher p values for power of conditional independence test
doanalysis_lm_S1 <- function(x){
  ## generate datasets and create missing values
  data <- datasample(x,n=2000)
  missdata <- makeMarlm(data,missratio=0.2)
  ## create output listing
  out <- list()
  out$full <- lmfull(data)
  data$sex <- as.numeric(data$sex)
  data$isced <- as.numeric(data$isced)
  ## conditional independence test (power) alpha <- 0.05
  Fisher.p <- gaussCItest(5,3,1,list(C = cor(data), 
                                     n = nrow(data)))
  ## correlation between log.waist and bmi given age
  pcor <- pcor(c(5,3,1),var(data))
  out$full <- cbind(out$full, 
                    Fisher.p=c(Fisher.p,rep("",9)),
                    pcor=c(pcor,rep("",9)))
  ## imputation using mice rf
  
  ## MICE RF 10
  setRFoptions(ntree_cat=10)
  options()$CALIBERrfimpute_ntree_cat
  mice.rf <- domice(missdata, c('rfcont10', '', 'rfcat', ''))
  out$rf10 <- lmimpute(mice.rf)
  ## convert longdata to transform data type as numeric
  long_rf10 <- complete(mice.rf, action='long', include=TRUE)
  long_rf10$sex <- as.numeric(long_rf10$sex)
  long_rf10$isced <- as.numeric(long_rf10$isced)
  # Convert back to Mids and calculate p-values
  short_rf10 <- as.mids(long_rf10)
  # Power: x=log.waist y=bmi z=age
  Fisher.p <- gaussCItestMI(5,3,1, short_rf10)
  out$rf10 <- cbind(out$rf10, Fisher.p=c(Fisher.p,rep("",9)))
  
  ## MICE RF 100
  setRFoptions(ntree_cat=100)
  options()$CALIBERrfimpute_ntree_cat
  micerf100 <- domice(missdata, c('rfcont100', '', 'rfcat', ''))
  out$rf100 <- lmimpute(micerf100)
  ## convert longdata to transform data type as numeric
  long_rf100 <- complete(micerf100, action='long', include=TRUE)
  long_rf100$sex <- as.numeric(long_rf100$sex)
  long_rf100$isced <- as.numeric(long_rf100$isced)
  # Convert back to Mids and calculate p-values
  short_rf100 <- as.mids(long_rf100)
  # Power: x=log.waist y=bmi z=age
  Fisher.p <- gaussCItestMI(5,3,1, short_rf100)
  out$rf100 <- cbind(out$rf100, Fisher.p=c(Fisher.p,rep("",9)))
  
  ## MICE PMM
  micepmm <- domice(missdata, c('pmm', '', 'pmm', ''))
  out$micepmm <- lmimpute(micepmm)
  ## convert longdata to transform data type as numeric
  long_pmm <- complete(micepmm, action='long', include=TRUE)
  long_pmm$sex <- as.numeric(long_pmm$sex)
  long_pmm$isced <- as.numeric(long_pmm$isced)
  # Convert back to Mids and calculate p-values
  short_pmm <- as.mids(long_pmm)
  # Power: x=log.waist y=bmi z=age
  Fisher.p <- gaussCItestMI(5,3,1, short_pmm)
  out$micepmm <- cbind(out$micepmm, Fisher.p=c(Fisher.p,rep("",9)))
  out
}

## Perform the simulation
N <- 1000
formular <- log.waist ~  age + bmi + sex + isced + sex:age + age:bmi
best.fit <- lm(log.waist ~  age + bmi + sex + isced + 
                 sex:age + age:bmi, data = data_complete)
consist_coef <- summary(best.fit)$coefficients[ ,1]
results_lm_S1 <- mclapply(1:N, doanalysis_lm_S1)

## calculate type 1 error of conditional independence test
## sample size n=200 miss%=0.05
doanalysis_CIT_S1 <- function(x){
  data <- dataCITerror(x,n=2000)
  missdata <- makeMarlm(data,missratio=0.2)
  ## create output listing
  out <- list()
  out$full <- lmfull(data)
  data$sex <- as.numeric(data$sex)
  data$isced <- as.numeric(data$isced)
  ## conditional independence test (power) alpha <- 0.05
  Fisher.p <- gaussCItest(5,3,1,list(C = cor(data), 
                                     n = nrow(data)))
  ## correlation between log.waist and bmi given age
  pcor <- pcor(c(5,3,1),var(data))
  out$full <- cbind(out$full, 
                    Fisher.p=c(Fisher.p,rep("",9)),
                    pcor=c(pcor,rep("",9)))

  ## imputation using mice rf
  ## MICE RF 10
  setRFoptions(ntree_cat=10)
  options()$CALIBERrfimpute_ntree_cat
  mice.rf <- domice(missdata, c('rfcont10', '', 'rfcat', ''))
  out$rf10 <- lmimpute(mice.rf)
  ## convert longdata to transform data type as numeric
  long_rf10 <- complete(mice.rf, action='long', include=TRUE)
  long_rf10$sex <- as.numeric(long_rf10$sex)
  long_rf10$isced <- as.numeric(long_rf10$isced)
  # Convert back to Mids and calculate p-values
  short_rf10 <- as.mids(long_rf10)
  # Power: x=log.waist y=bmi z=age
  Fisher.p <- gaussCItestMI(5,3,1, short_rf10)
  out$rf10 <- cbind(out$rf10, Fisher.p=c(Fisher.p,rep("",9)))
  
  ## MICE RF 100
  setRFoptions(ntree_cat=100)
  options()$CALIBERrfimpute_ntree_cat
  micerf100 <- mice(missdata, 
                    meth = c("rfcont100","rfcat","rfcont100",
                             "rfcat","rfcont100"), m = 10, 
                    visitSequence = 'monotone',
                    printFlag = FALSE, maxit = 9)
  out$rf100 <- lmimpute(micerf100)
  ## convert longdata to transform data type as numeric
  long_rf100 <- complete(micerf100, action='long', include=TRUE)
  long_rf100$sex <- as.numeric(long_rf100$sex)
  long_rf100$isced <- as.numeric(long_rf100$isced)
  # Convert back to Mids and calculate p-values
  short_rf100 <- as.mids(long_rf100)
  # Power: x=log.waist y=bmi z=age
  Fisher.p <- gaussCItestMI(5,3,1, short_rf100)
  out$rf100 <- cbind(out$rf100, Fisher.p=c(Fisher.p,rep("",9)))
  
  ## MICE PMM
  micepmm <- mice(missdata, 
                  meth = c("pmm","pmm","pmm","pmm","pmm"), m = 10, 
                  visitSequence = 'monotone',
                  printFlag = FALSE, maxit = 10)
  out$micepmm <- lmimpute(micepmm)
  ## convert longdata to transform data type as numeric
  long_pmm <- complete(micepmm, action='long', include=TRUE)
  long_pmm$sex <- as.numeric(long_pmm$sex)
  long_pmm$isced <- as.numeric(long_pmm$isced)
  # Convert back to Mids and calculate p-values
  short_pmm <- as.mids(long_pmm)
  # Power: x=log.waist y=bmi z=age
  Fisher.p <- gaussCItestMI(5,3,1, short_pmm)
  out$micepmm <- cbind(out$micepmm, Fisher.p=c(Fisher.p,rep("",10)))
  out
}

## Perform the simulation
N <- 1000
results_CIT_S1 <- mclapply(1:N, doanalysis_CIT_S1)

#-------------------------------------------------------------------------#
#                            Analysis Setting 2                           #
#-------------------------------------------------------------------------#
## Setting 2 is  basically similar to Setting 1
## The changes are ample size n, missing ratio and without rf100
## linear regression: methods comparation using list
## Calculate Fisher p values for power of conditional independence test
doanalysis_lm_S2 <- function(x){
  ## generate datasets and create missing values
  ## n is changed to 1000 and  missratio is changed to 0.05
  data <- datasample(x,n=200)
  missdata <- makeMarlm(data,missratio=0.2)
  ## create output listing
  out <- list()
  out$full <- lmfull(data)
  data$sex <- as.numeric(data$sex)
  data$isced <- as.numeric(data$isced)
  ## conditional independence test (power) alpha <- 0.05
  Fisher.p <- gaussCItest(5,3,1,list(C = cor(data), n = nrow(data)))
  ## correlation between log.waist and bmi given age
  pcor <- pcor(c(5,3,1),var(data))
  out$full <- cbind(out$full, 
                    Fisher.p=c(Fisher.p,rep("",9)),
                    pcor=c(pcor,rep("",9)))
  
  ## imputation using mice rf
  ## MICE RF 10
  setRFoptions(ntree_cat=10)
  options()$CALIBERrfimpute_ntree_cat
  mice.rf <- domice(missdata, c('rfcont10', '', 'rfcat', ''))
  out$rf10 <- lmimpute(mice.rf)
  ## convert longdata to transform data type as numeric
  long_rf10 <- complete(mice.rf, action='long', include=TRUE)
  long_rf10$sex <- as.numeric(long_rf10$sex)
  long_rf10$isced <- as.numeric(long_rf10$isced)
  # Convert back to Mids and calculate p-values
  short_rf10 <- as.mids(long_rf10)
  # Power: x=log.waist y=bmi z=age
  Fisher.p <- gaussCItestMI(5,3,1, short_rf10)
  out$rf10 <- cbind(out$rf10, Fisher.p=c(Fisher.p,rep("",9)))
  
  ## MICE PMM
  micepmm <- domice(missdata, c('pmm', '', 'pmm', ''))
  out$micepmm <- lmimpute(micepmm)
  ## convert longdata to transform data type as numeric
  long_pmm <- complete(micepmm, action='long', include=TRUE)
  long_pmm$sex <- as.numeric(long_pmm$sex)
  long_pmm$isced <- as.numeric(long_pmm$isced)
  # Convert back to Mids and calculate p-values
  short_pmm <- as.mids(long_pmm)
  # Power: x=log.waist y=bmi z=age
  Fisher.p <- gaussCItestMI(5,3,1, short_pmm)
  out$micepmm <- cbind(out$micepmm, Fisher.p=c(Fisher.p,rep("",9)))
  out
}

## Perform the simulation
N <- 1000
results_lm_S2 <- mclapply(1:N, doanalysis_lm_S2)

## calculate type 1 error of conditional independence test
doanalysis_CIT_S2 <- function(x){
  data <- dataCITerror(x,n=1000)
  missdata <- makeMarlm(data,missratio=0.2)
  ## create output listing
  out <- list()
  data$sex <- as.numeric(data$sex)
  data$isced <- as.numeric(data$isced)
  ## conditional independence test (power) alpha <- 0.05
  Fisher.p <- gaussCItest(5,3,1,list(C = cor(data), n = nrow(data)))
  ## correlation between log.waist and bmi given age
  pcor <- pcor(c(5,3,1),var(data))
  out$full <- cbind(NULL, 
                    Fisher.p=c(Fisher.p,rep("",9)),
                    pcor=c(pcor,rep("",9)))
  
  ## imputation using mice rf
  ## MICE RF 10
  setRFoptions(ntree_cat=10)
  options()$CALIBERrfimpute_ntree_cat
  mice.rf <- domice(missdata, c('rfcont10', '', 'rfcat', ''))
  ## convert longdata to transform data type as numeric
  long_rf10 <- complete(mice.rf, action='long', include=TRUE)
  long_rf10$sex <- as.numeric(long_rf10$sex)
  long_rf10$isced <- as.numeric(long_rf10$isced)
  # Convert back to Mids and calculate p-values
  short_rf10 <- as.mids(long_rf10)
  # Power: x=log.waist y=bmi z=age
  Fisher.p <- gaussCItestMI(5,3,1, short_rf10)
  out$rf10 <- cbind(NULL, Fisher.p=c(Fisher.p,rep("",9)))

  ## MICE PMM
  micepmm <- mice(missdata, 
                  meth = c("pmm","pmm","pmm","pmm","pmm"), m = 10, 
                  visitSequence = 'monotone',
                  printFlag = FALSE, maxit = 10)
  ## convert longdata to transform data type as numeric
  long_pmm <- complete(micepmm, action='long', include=TRUE)
  long_pmm$sex <- as.numeric(long_pmm$sex)
  long_pmm$isced <- as.numeric(long_pmm$isced)
  # Convert back to Mids and calculate p-values
  short_pmm <- as.mids(long_pmm)
  # Power: x=log.waist y=bmi z=age
  Fisher.p <- gaussCItestMI(5,3,1, short_pmm)
  out$micepmm <- cbind(NULL, Fisher.p=c(Fisher.p,rep("",9)))
  out
}

## Perform the simulation
N <- 1000
results_CIT_S2 <- mclapply(1:N, doanalysis_CIT_S2)

#-------------------------------------------------------------------------#
#                            Analysis Setting 3                           #
#-------------------------------------------------------------------------#
## linear regression: methods comparation using list
## Calculate Fisher p values for power of conditional independence test
doanalysis_lm_S3 <- function(x){
  ## generate datasets and create missing values
  data <- datasample(x,n=2000)
  missdata <- makeMarlm(data,missratio=0.2)
  ## create output listing
  out <- list()
  out$full <- lmfull(data)
  data$sex <- as.numeric(data$sex)
  data$isced <- as.numeric(data$isced)
  ## conditional independence test (power) alpha <- 0.05
  Fisher.p <- gaussCItest(5,3,1,list(C = cor(data), n = nrow(data)))
  ## correlation between log.waist and bmi given age
  pcor <- pcor(c(5,3,1),var(data))
  out$full <- cbind(out$full, 
                    Fisher.p=c(Fisher.p,rep("",9)),
                    pcor=c(pcor,rep("",9)))
  
  ## imputation using mice rf
  ## MICE RF 10
  setRFoptions(ntree_cat=10)
  options()$CALIBERrfimpute_ntree_cat
  mice.rf <- domice(missdata, c('rfcont10', '', 'rfcat', ''))
  out$rf10 <- lmimpute(mice.rf)
  ## convert longdata to transform data type as numeric
  long_rf10 <- complete(mice.rf, action='long', include=TRUE)
  long_rf10$sex <- as.numeric(long_rf10$sex)
  long_rf10$isced <- as.numeric(long_rf10$isced)
  # Convert back to Mids and calculate p-values
  short_rf10 <- as.mids(long_rf10)
  # Power: x=log.waist y=bmi z=age
  Fisher.p <- gaussCItestMI(5,3,1, short_rf10)
  out$rf10 <- cbind(out$rf10, Fisher.p=c(Fisher.p,rep("",9)))
  
  ## generate interaction terms and non-linear terms for passive imputaton
  missdata$sex <- as.numeric(missdata$sex)
  missdata$isced <- as.numeric(missdata$isced)
  missdata <- cbind(missdata, 
                    age.sex = NA, age.bmi = NA, age.isced = NA,
                    age.waist = NA, sex.bmi = NA, sex.isced = NA,
                    sex.waist = NA, bmi.isced = NA, bmi.waist = NA,
                    isced.waist = NA, 
                    age.age = NA, bmi.bmi = NA, waist.waist = NA)
  ## change the method and prediction for interactionterm, 
  ## using interaction term to predict vaiable bmi isced
  S3 <- mice(missdata, max = 0, print = FALSE)
  pred <- S3$pred
  pred["age",   c("sex.bmi","sex.isced","sex.waist","bmi.isced",
                  "bmi.waist","isced.waist","bmi.bmi","waist.waist")] <- 1
  pred["bmi",   c("age.sex","age.isced","age.waist","sex.isced",
                  "sex.waist","isced.waist","age.age","waist.waist")] <- 1
  pred["isced", c("age.sex","age.bmi","age.waist","sex.bmi","sex.waist",
                  "bmi.waist","age.age","bmi.bmi","waist.waist")] <- 1
  
  ## MICE PMM
  meth_pmm <- c("pmm","","pmm","pmm","",
                "~I(age*sex)","~I(age*bmi)","~I(age*isced)",
                "~I(age*log.waist)","~I(sex*bmi)","~I(sex*isced)",
                "~I(sex*log.waist)","~I(bmi*isced)","~I(bmi*log.waist)",
                "~I(isced*log.waist)","~I(age*age)","~I(bmi*bmi)",
                "~I(log.waist*log.waist)")
  mice.pmm <- mice(missdata, meth = meth_pmm, pred = pred, m = 10, 
                   visitSequence = 'monotone',
                   printFlag = FALSE, maxit = 10)
  ## Check the imputed dataset
  ## head(complete(mice.pmm,2))
  ## Power: x=log.waist y=bmi z=age
  Fisher.p <- gaussCItestMI(5,3,1, mice.pmm)
  ## Convert sex and isced to factor
  long_pmm <- complete(mice.pmm, action='long', include=TRUE)
  long_pmm$sex <- as.factor(long_pmm$sex)
  long_pmm$isced <- as.factor(long_pmm$isced)
  short_pmm <- as.mids(long_pmm)
  ## Linear regression estimation
  out$micepmm <- lmimpute(short_pmm)
  out$micepmm <- cbind(out$micepmm, 
                       Fisher.p=c(Fisher.p,rep("",9)))
  out
}

## Perform the simulation
N <- 1000
results_lm_S3 <- mclapply(1:N, doanalysis_lm_S3)

## calculate type 1 error of conditional independence test
doanalysis_CIT_S3 <- function(x){
  data <- dataCITerror(x,n=2000)
  missdata <- makeMarlm(data,missratio=0.2)
  ## create output listing
  out <- list()
  data$sex <- as.numeric(data$sex)
  data$isced <- as.numeric(data$isced)
  ## conditional independence test (power) alpha <- 0.05
  Fisher.p <- gaussCItest(5,3,1,list(C = cor(data), n = nrow(data)))
  ## correlation between log.waist and bmi given age
  pcor <- pcor(c(5,3,1),var(data))
  out$full <- cbind(NULL, 
                    Fisher.p=c(Fisher.p,rep("",9)),
                    pcor=c(pcor,rep("",9)))

  ## imputation using mice rf
  ## MICE RF 10
  setRFoptions(ntree_cat=10)
  options()$CALIBERrfimpute_ntree_cat
  mice.rf <- domice(missdata, c('rfcont10', '', 'rfcat', ''))
  ## convert longdata to transform data type as numeric
  long_rf10 <- complete(mice.rf, action='long', include=TRUE)
  long_rf10$sex <- as.numeric(long_rf10$sex)
  long_rf10$isced <- as.numeric(long_rf10$isced)
  # Convert back to Mids and calculate p-values
  short_rf10 <- as.mids(long_rf10)
  # Power: x=log.waist y=bmi z=age
  Fisher.p <- gaussCItestMI(5,3,1, short_rf10)
  out$rf10 <- cbind(NULL, Fisher.p=c(Fisher.p,rep("",9)))
  
  ## generate interaction terms and non-linear terms for passive imputaton
  missdata$sex <- as.numeric(missdata$sex)
  missdata$isced <- as.numeric(missdata$isced)
  missdata <- cbind(missdata, 
                    age.sex = NA, age.bmi = NA, age.isced = NA,
                    age.waist = NA, sex.bmi = NA, sex.isced = NA,
                    sex.waist = NA, bmi.isced = NA, bmi.waist = NA,
                    isced.waist = NA, 
                    age.age = NA, bmi.bmi = NA, waist.waist = NA)
  ## change the method and prediction for interactionterm, 
  ## using interaction term to predict vaiable bmi isced
  S3 <- mice(missdata, max = 0, print = FALSE)
  pred <- S3$pred
  pred["age",   c("sex.bmi","sex.isced","sex.waist","bmi.isced",
                  "bmi.waist","isced.waist","bmi.bmi","waist.waist")] <- 1
  pred["bmi",   c("age.sex","age.isced","age.waist","sex.isced",
                  "sex.waist","isced.waist","age.age","waist.waist")] <- 1
  pred["isced", c("age.sex","age.bmi","age.waist","sex.bmi","sex.waist",
                  "bmi.waist","age.age","bmi.bmi","waist.waist")] <- 1
  
  ## MICE PMM
  meth_pmm <- c("pmm","","pmm","pmm","",
                "~I(age*sex)","~I(age*bmi)","~I(age*isced)",
                "~I(age*log.waist)","~I(sex*bmi)","~I(sex*isced)",
                "~I(sex*log.waist)","~I(bmi*isced)","~I(bmi*log.waist)",
                "~I(isced*log.waist)","~I(age*age)","~I(bmi*bmi)",
                "~I(log.waist*log.waist)")
  mice.pmm <- mice(missdata, meth = meth_pmm, pred = pred, m = 10, 
                   visitSequence = 'monotone',
                   printFlag = FALSE, maxit = 10)
  Fisher.p <- gaussCItestMI(5,3,1, mice.pmm)
  out$micepmm <- cbind(NULL, 
                       Fisher.p=c(Fisher.p,rep("",9)))
  out
}

## Perform the simulation
N <- 1000
results_CIT_S3 <- mclapply(1:N, doanalysis_CIT_S3)
```

```R
#-------------------------------------------------------------------------#
#                 Compare Results: Linear Regression                      #
#-------------------------------------------------------------------------#
## Results: Linear Regression Performance
getParameter_lm <- function(method){
  ## draw the coefficient estimators
  estimates <- sapply(results, function(x){
    as.numeric(x[[method]][ , 'est'])
  })
  ## calculate bias of estimators 
  bias <- apply(estimates,1,mean) - consist_coef
  ## calculate the standard error 
  se_bias <- apply(estimates,1,sd) / sqrt(ncol(estimates))
  ## calculate z score
  z <- bias / se_bias
  ## confidence interval length
  ci_len <- apply(sapply(results, function(x){
    as.numeric(x[[method]][ , 'hi 95']) - 
      as.numeric(x[[method]][ , 'lo 95'])
  }),1,mean)
  ## coverage of the unbiased estimators
  ci_cov <- apply(sapply(results, function(x){
    as.numeric(x[[method]][ , 'cover'])
  }),1,mean)
  ## summary the output and rename
  out <- cbind(bias, se_bias, z, ci_len, ci_cov)
  colnames(out) <- c('bias', 'se_bias', 'z_bias', 
                     'ci_len', 'ci_cov')
  out
}

Table_lm <- function(x,n){
  results_lm <- lapply(methods, 
                       function(x){getParameter_lm(x)})
  ## convert list to data.frame
  results_lm <- do.call(rbind.data.frame, results_lm)
  ## reorder
  results_lm <- cbind(results_lm, 
                      order1=rep(1:10,time=n),
                      order2=rep(1:n,each=10))
  results_lm <- results_lm[order(results_lm$order1,
                                 results_lm$order2),]
  ## format the names
  results_lm <- cbind(Variables=c('Intercept',rep('',n-1),
                                  'Age',rep('',n-1),
                                  'BMI',rep('',n-1),
                                  'Sex',rep('',n-1),
                                  'ISCED[2]',rep('',n-1),
                                  'ISCED[3]',rep('',n-1),
                                  'ISCED[4]',rep('',n-1),
                                  'ISCED[5]',rep('',n-1),
                                  'Age:Sex',rep('',n-1),
                                  'Age:BMI',rep('',n-1)),
                      Nodell=Model_names,
                      results_lm[,c(1,2,3,4,5)])
  ## format the decimal
  results_lm$bias <- round(results_lm$bias, 4)
  results_lm$se_bias <- round(results_lm$se_bias, 4)
  results_lm$z_bias <- round(results_lm$z_bias, 4)
  results_lm$ci_len <- round(results_lm$ci_len, 4)
  library(formattable)
  results_lm$ci_cov <- percent(results_lm$ci_cov,digits = 1)
  colnames(results_lm) <- c('Variables','Models','Bias', 
                            'SD', 
                            'Z-score', 
                            'CI length', 
                            'CI coverage')
  rownames(results_lm) <- NULL
  return(results_lm)
}

## Conduct analysis: take setting 1 as an example
methods <- c('full', 'rf10', 'rf100', 'micepmm')
Model_names <- rep(c("Full data","RF MICE with 10 trees",
                     "RF MICE with 100 trees",
                     "Parametric MICE PMM"),
                   times=10)
results <- results_lm_S1
resultsTable_lm_S1 <- Table_lm(results_lm_S1,4)

#-------------------------------------------------------------------------#
#             Compare Results: Conditional independence test              #
#-------------------------------------------------------------------------#
## Results: Conditional Independence Test
getParameter_CIT <- function(method){
  ## draw the coefficient estimators
  Fisher.p <- sapply(results, function(x){
    as.numeric(x[[method]][ , 'Fisher.p'])
  })
  Fisher.p <- Fisher.p[1,]
  cover <- ifelse(Fisher.p <= 0.05,1,0)
  cover_ratio <- mean(cover)
  cover_ratio
}

Table_CIT <- function(x){
  results_CIT <- lapply(methods, 
                        function(x){getParameter_CIT(x)})
  ## convert list to data.frame
  results_CIT <- do.call(rbind.data.frame, results_CIT)
  ## format the names
  results_CIT <- cbind(Modell=Model_names,
                       results_CIT)
  colnames(results_CIT) <- c('Models','Ratio')
  rownames(results_CIT) <- NULL
  ## format the decimal
  library(formattable)
  results_CIT$Ratio <- percent(results_CIT$Ratio,digits = 2)
  return(results_CIT)
}

## Conduct analysis: take setting 1 as an example
methods <- c('rf10', 'rf100', 'micepmm')
Model_names <- c("RF MICE with 10 trees",
                 "RF MICE with 100 trees",
                 "Parametric MICE PMM")
results <- results_lm_S1
lm <- Table_CIT(results_lm_S1)
results <- results_CIT_S1
CIT <- Table_CIT(results_CIT_S1)
resultsTable_CIT_S1 <- cbind(lm,CIT)[,-3]
colnames(resultsTable_CIT_S1) <- c('Models','Power','Type 1 error')
```






# References

Rubin D. (1976). Inference and missing data. Biometrika, Volume 63, Issue 3, Pages 581–592.

Rubin, Donald B. (1986). Statistical Matching Using File Concatenation with Adjusted Weights and Multiple Imputations. Journal of Business Economics and Statistics 4 (1): 87–94.

Little, Roderick J. A. (1988). Missing-Data Adjustments in Large Surveys. Journal of Business & Economic Statistics. 6 (3): 287–296.

Meng, Xiao-Li. (1994). Multiple-Imputation Inferences with Uncongenial Sources of Input. Rejoinder. Statist. Sci. 9 , no. 4, 566--573.

Tin Kam Ho. (1995). "Random decision forests," Proceedings of 3rd International Conference on Document Analysis and Recognition, Montreal, Quebec, Canada, pp. 278-282.

Schafer JL. (1997). Analysis of Incomplete Multivariate Data. Chapman & Hall: London.

Schafer JL,  Olsen MK. (1998). Multiple imputation for multivariate missing-data problems: a data analyst's perspective, Multivariate Behav Res., vol. 33 4(pg. 545-571)

Barnard J, Rubin D. (1999). Small-sample degrees of freedom with multiple imputation. Biometrika. 86(4):948–955.

Breiman, Leo. (2001). Statistical Modeling: The Two Cultures (with comments and a rejoinder by the author). Statist. Sci. 16, no. 3, 199--231.

Roderick J. A. Little Donald B. Rubin. (2002). Statistical Analysis with Missing Data, Second Edition.

Van Buuren, S., J.P.L. Brand, C.G.M.Groothuis-Oudshoorn, and D.B. Rubin. (2006). Fully conditional specification in multivariate imputation. Journal of Statistical Computation and Simulation 76 (12): 1049–64.

Ludwig Fahrmeir, Stefan M. Lang, Thomas Kneib. (2007). Regression: Models, Methods and Applications.

Carlin, Bradley P.; Louis, Thomas A. (2008). Bayesian Methods for Data Analysis, Third Edition. Boca Raton, FL: Chapman and Hall/CRC.

Ishwaran H, Kogalur UB, Blackstone EH, Lauer MS. (2008). Random survival forests. Ann Appl Stat. 2: 841–860. 

Ian R. White, Patrick Royston, Angela M. Wood. (2009). Multiple imputation using chained equations: Issues and guidance for practice. Statistics in medicine 30(4):377–399.

Yulei He & Trivellore E. Raghunathan. (2009). On the Performance of Sequential Regression Multiple Imputation Methods with Non Normal Error Distributions, Communications in Statistics - Simulation and Computation, 38:4, 856-883.

Hippel, P.V. (2009). HOW TO IMPUTE INTERACTIONS, SQUARES, AND OTHER TRANSFORMED VARIABLES. Sociological Methodology, 39, 265-291.

Marshall A, Altman DG, Royston P, Holder RL. (2010). Comparison of techniques for handling missing covariate data within prognostic modelling studies: a simulation study. BMC Med Res Methodol. 10:7. Published 2010 Jan 19.

Lane F. Burgette, Jerome P. Reiter. (2010). Multiple Imputation for Missing Data via Sequential Regression Trees. American Journal of Epidemiology, Volume 172, Issue 9, Pages 1070–1076.

Deng H., Runger G., Tuv E. (2011). Bias of Importance Measures for Multi-valued Attributes and Solutions. In: Honkela T., Duch W., Girolami M., Kaski S. (eds) Artificial Neural Networks and Machine Learning – ICANN 2011. ICANN 2011. Lecture Notes in Computer Science, vol 6792. Springer, Berlin, Heidelberg.

Loh, P., Wainwright, M. (2011). High-dimensional regression with noisy and missing data: Provable guarantees with non-convexity. ArXiv, pp. 2726–2734. 

ISCED. (2011). International Standard Classification of Education ISCED 2011. (Accessed October 03, 2020)

Daniel J. Stekhoven, Peter Bühlmann. (2012). MissForest—non-parametric missing value imputation for mixed-type data. Bioinformatics, Volume 28, Issue 1, Pages 112–118.

Oshiro, Thais & Perez, Pedro & Baranauskas, José. (2012). How Many Trees in a Random Forest?. Lecture notes in computer science. 7376.

Stekhoven DJ. (2012). missForest: Nonparametric Missing Value Imputation using Random Forest. Vienna, Austria: Comprehensive R Archive Network. (Accessed May 15, 2020)

Seaman SR, Bartlett JW, White IR. (2012). Multiple imputation of missing covariates with non-linear effects and interactions: an evaluation of statistical methods. BMC Med Res Methodol. 12:46. Published 2012 Apr 10.

Van Buuren, S. (2012). Flexible Imputation of Missing Data. Chapman and Hall/CRC Press.

Cole TJ, Lobstein T. (2012). Extended international (IOTF) body mass index cut-offs for thinness, overweight and obesity. Pediatr Obes. 7(4):284-94.

Hardt J, Herke M, Leonhart R. (2012). Auxiliary variables in multiple imputation in regression with missing X: a warning against including too many in small sample research. BMC Med Res Methodol. 12(1):184. 

Burgess S, White IR, Resche-Rigon M, Wood AM. (2013). Combining multiple imputation and meta-analysis with individual participant data. Stat Med.;32(26):4499‐4514.

Waljee, A. K., A. Mukherjee, A. G. Singal, Y. Zhang, J. Warren, U. Balis, J. Marrero, J. Zhu, and P. D. R. Higgins. (2013). Comparison of Imputation Methods for Missing Laboratory Data in Medicine. BMJ Open 3 (8): e002847.

Shah AD. (2013). CALIBERrfimpute: Imputation in MICE using Random Forest. Vienna, Austria: Comprehensive R Archive Network; 2013. R package, version 0.1-2).

Gareth James, Daniela Witten, Trevor Hastie, and Robert Tibshirani. (2014). An Introduction to Statistical Learning: with Applications in R. Springer Publishing Company, Incorporated.

L.L. Doove, S. Van Buuren, E. Dusseldorp. (2014). Recursive partitioning for missing data imputation in the presence of interaction effects. Computational Statistics & Data Analysis, Volume 72, Pages 92-104, ISSN 0167-9473.

Hughes RA, White IR, Seaman SR, Carpenter JR, Tilling K, Sterne JA. (2014). Joint modelling rationale for chained equations. BMC Med Res Methodol. 14:28. Published 2014 Feb 21.

Shah AD, Bartlett JW, Carpenter J, Nicholas O, Hemingway H. (2014). Comparison of random forest and parametric imputation models for imputing missing data using MICE: a CALIBER study. Am J Epidemiol, 179(6):764–774.

Ziegler, König. (2014). Mining data with random forests: current options for real-world applications. WIREs Data Mining and Knowledge Discovery, 4(1):55–63.

Jonathan Bartlett. (2014). Methodology for multiple imputation for missing data in electronic health record data. International Biometric Conference. (Accessed November 12, 2020)

Bartlett, J.W. et al., (2015). Multiple imputation of covariates by fully conditional specification: Accommodating the substantive model. Statistical methods in medical research, 24(4), pp.462–487.

Morris, Tim. (2015). Multiple Imputation of Covariates by Substantive-model Compatible Fully Conditional Specification. Stata Journal. 15. 437–456.

Tilling, Williamson, Spratt, Sterne, Carpenter. (2016). Appropriate inclusion of interactions was needed to avoid bias in multiple imputation.Journal of clinical epidemiology vol, 80:107-115. 

Fei Tang, Hemant Ishwaran. (2017). Random Forest Missing Data Algorithms.Stat Anal Data Min, 10(6):363–377.

Kropko, J., Goodrich, B., Gelman, A., & Hill, J. (2017). Multiple Imputation for Continuous and Categorical Data: Comparing Joint Multivariate Normal and Conditional Approaches. Political Analysis, 22(4), 497-519.

Ahrens W, Siani A, Adan R, et al. (2017). Cohort Profile: The transition from childhood to adolescence in European children-how I.Family extends the IDEFICS cohort. Int J Epidemiol. 2017;46(5):1394‐1395j.

Schouten, R.M., Lugtig, P.L., and Vink, G. (2018). Generating missing values for simulation purposes: a multivariate amputation procedure, Journal of Statistical Computation and Simulation, 88:15, 2909-2930.

Runmin Wei, Jingye Wang. (2018). Missing Value Imputation Approach for Mass Spectrometry-based Metabolomics Data. Scientific Reports, 8(1):663.

Salfrán Vaquero, Daniel. (2018). Multiple Imputation for Complex Data Sets. Dissertation, University of Hamburg.

Murray, J. (2018). Multiple Imputation: A Review of Practical and Theoretical Findings. arXiv: Methodology.

Marietta Kokla, Jyrki Virtanen, Marjukka Kolehmainen, Jussi Paananen & Kati Hanhineva. (2019). Random forest-based imputation outperforms other methods for imputing LC-MS metabolomics data: a comparative study. BMC Bioinformatics, 20:492.

Emily Slade  Melissa G. Naylor. (2020). A fair comparison of tree-based and parametric methods in multiple imputation by chained equations.Statistics in medicine, 39:1156–1166.

Foraita, R., Friemel, J., Guenther, K., Behrens, T., Bullerdiek, J., Nimzyk, R., Ahrens, W., & Didelez, V. (2020). Causal discovery of gene regulation with incomplete data. Journal of The Royal Statistical Society Series A-statistics in Society.

Multiple imputation in STATA. https://stats.idre.ucla.edu/stata/seminars/mi_in_stata_pt1_new/. (Accessed October 21, 2020).

<!-- These lines ensure references are set with hanging indents in PDF documents -->
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}


